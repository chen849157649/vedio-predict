{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total cpu count 8\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from lightgbm.sklearn import LGBMClassifier\n",
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "from scipy.stats import entropy\n",
    "from gensim.models import Word2Vec\n",
    "import time\n",
    "import gc\n",
    "import os\n",
    "\n",
    "import tqdm                                                                                                   \n",
    "import concurrent.futures\n",
    "import multiprocessing\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "num_processes = multiprocessing.cpu_count()\n",
    "print(\"total cpu count\", +num_processes) \n",
    "\n",
    "os.environ['NUMEXPR_MAX_THREADS'] = '8'\n",
    "\n",
    "from core.utils import timeit, reduce_mem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/media/ryan/F/deep-learning-data/turing/vedio-predict/\"\n",
    "\n",
    "path_sub = path + 'sub/'\n",
    "path_npy = path + 'npy/'\n",
    "path_data = path + 'raw/'\n",
    "path_model = path + 'model/'\n",
    "path_result = path + 'result/'\n",
    "path_pickle = path + 'pickle/'\n",
    "path_profile = path + 'profile/'\n",
    "\n",
    "debug_small = False\n",
    "\n",
    "if debug_small:\n",
    "    train_df = pd.read_pickle(path_pickle + 'train_small.pickle')\n",
    "    test_df = pd.read_pickle(path_pickle + 'test_small.pickle')\n",
    "    sub = pd.read_csv(path_data + 'sample.csv')\n",
    "\n",
    "    # app = pd.read_pickle(path_pickle + 'app_small.pickle')\n",
    "    # user = pd.read_pickle(path_pickle + 'user_small.pickle')\n",
    "else:\n",
    "    train_df = pd.read_pickle(path_pickle + 'train.pickle')\n",
    "    test_df = pd.read_pickle(path_pickle + 'test.pickle')\n",
    "    sub = pd.read_csv(path_data + 'sample.csv')\n",
    "\n",
    "    # app = pd.read_pickle(path_pickle + 'app.pickle')\n",
    "    # user = pd.read_pickle(path_pickle + 'user.pickle')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df = train_df[train_df.deviceid.str[-1] == '1']\n",
    "# test_df = test_df[test_df.deviceid.str[-1] == '1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sub = sub[sub.id.isin(test_df.id) ]\n",
    "# sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================================== read train ===============================================\n",
      "runtime: 22.337076902389526\n"
     ]
    }
   ],
   "source": [
    "print('=============================================== read train ===============================================')\n",
    "t = time.time()\n",
    "# train_df = pd.read_csv('dataset/train.csv')\n",
    "train_df['date'] = pd.to_datetime(\n",
    "    train_df['ts'].apply(lambda x: time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(x / 1000)))\n",
    ")\n",
    "train_df['day'] = train_df['date'].dt.day\n",
    "\n",
    "# 训练集中，day=7的个数为11个，day=8的为3,674,871。 day9，10也是解决40w\n",
    "# day=7占比不到1/百万，属于异常情况，去掉合理？ 线上的表现又会如何，为啥不是直接删除，这样有点过了\n",
    "# 这里为啥只是改了day，不去直接改ts和timestamp呢？\n",
    "train_df.loc[train_df['day'] == 7, 'day'] = 8\n",
    "train_df['hour'] = train_df['date'].dt.hour\n",
    "train_df['minute'] = train_df['date'].dt.minute\n",
    "train_num = train_df.shape[0]\n",
    "labels = train_df['target'].values\n",
    "print('runtime:', time.time() - t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11376681"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df =pd.read_pickle(path_pickle + \"df_081_emd_all.pickle\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_num =11376681\n",
    "cate_cols = [\n",
    "    'deviceid', 'newsid', 'pos', 'app_version', 'device_vendor',\n",
    "    'netmodel', 'osversion', 'device_version', 'lng', 'lat', 'lng_lat'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================== prepare train & valid  =============================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('======================================== prepare train & valid  =============================================')\n",
    "train_df = df[:train_num].reset_index(drop=True)\n",
    "test_df = df[train_num:].reset_index(drop=True)\n",
    "del df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11376681, 317)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runtime: 238.82718586921692\n",
      "========================================================================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "train_idx = train_df[train_df['day'] < 10].index.tolist()\n",
    "val_idx = train_df[train_df['day'] == 10].index.tolist()\n",
    "\n",
    "train_x = train_df.iloc[train_idx].reset_index(drop=True)\n",
    "train_y = labels[train_idx]\n",
    "val_x = train_df.iloc[val_idx].reset_index(drop=True)\n",
    "val_y = labels[val_idx]\n",
    "\n",
    "del train_x['day'], val_x['day'], train_df['day'], test_df['day']\n",
    "gc.collect()\n",
    "print('runtime:', time.time() - t)\n",
    "print('========================================================================================================')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learning_rate_callback(env):\n",
    "    delta_lr = 0.0001\n",
    "    iteration = env.iteration\n",
    "    if iteration % 10 == 0:\n",
    "        learning_rate = env.params['learning_rate'] - delta_lr\n",
    "        env.params['learning_rate'] = learning_rate\n",
    "        \n",
    "        print('---- current learning rate:' + str(learning_rate) + '----')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================================== training validate ===============================================\n",
      "************** training **************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ryan/anaconda3/envs/tensorflow/lib/python3.6/site-packages/lightgbm/basic.py:1295: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is ['app_version', 'device_vendor', 'device_version', 'deviceid', 'lat', 'lng', 'lng_lat', 'netmodel', 'newsid', 'osversion', 'pos']\n",
      "  'New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- current learning rate:0.0199----\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "---- current learning rate:0.0198----\n",
      "---- current learning rate:0.019700000000000002----\n",
      "---- current learning rate:0.019600000000000003----\n",
      "---- current learning rate:0.019500000000000003----\n",
      "[50]\tvalid_0's auc: 0.970956\n",
      "---- current learning rate:0.019400000000000004----\n",
      "---- current learning rate:0.019300000000000005----\n",
      "---- current learning rate:0.019200000000000005----\n",
      "---- current learning rate:0.019100000000000006----\n",
      "---- current learning rate:0.019000000000000006----\n",
      "[100]\tvalid_0's auc: 0.97365\n",
      "---- current learning rate:0.018900000000000007----\n",
      "---- current learning rate:0.018800000000000008----\n",
      "---- current learning rate:0.01870000000000001----\n",
      "---- current learning rate:0.01860000000000001----\n",
      "---- current learning rate:0.01850000000000001----\n",
      "[150]\tvalid_0's auc: 0.975558\n",
      "---- current learning rate:0.01840000000000001----\n",
      "---- current learning rate:0.01830000000000001----\n",
      "---- current learning rate:0.01820000000000001----\n",
      "---- current learning rate:0.018100000000000012----\n",
      "---- current learning rate:0.018000000000000013----\n",
      "[200]\tvalid_0's auc: 0.976839\n",
      "---- current learning rate:0.017900000000000013----\n",
      "---- current learning rate:0.017800000000000014----\n",
      "---- current learning rate:0.017700000000000014----\n",
      "---- current learning rate:0.017600000000000015----\n",
      "---- current learning rate:0.017500000000000016----\n",
      "[250]\tvalid_0's auc: 0.977515\n",
      "---- current learning rate:0.017400000000000016----\n",
      "---- current learning rate:0.017300000000000017----\n",
      "---- current learning rate:0.017200000000000017----\n",
      "---- current learning rate:0.017100000000000018----\n",
      "---- current learning rate:0.01700000000000002----\n",
      "[300]\tvalid_0's auc: 0.977994\n",
      "---- current learning rate:0.01690000000000002----\n",
      "---- current learning rate:0.01680000000000002----\n",
      "---- current learning rate:0.01670000000000002----\n",
      "---- current learning rate:0.01660000000000002----\n",
      "---- current learning rate:0.01650000000000002----\n",
      "[350]\tvalid_0's auc: 0.978334\n",
      "---- current learning rate:0.016400000000000022----\n",
      "---- current learning rate:0.016300000000000023----\n",
      "---- current learning rate:0.016200000000000023----\n",
      "---- current learning rate:0.016100000000000024----\n",
      "---- current learning rate:0.016000000000000025----\n",
      "[400]\tvalid_0's auc: 0.978493\n",
      "---- current learning rate:0.015900000000000025----\n",
      "---- current learning rate:0.015800000000000026----\n",
      "---- current learning rate:0.015700000000000026----\n",
      "---- current learning rate:0.015600000000000027----\n",
      "---- current learning rate:0.015500000000000028----\n",
      "[450]\tvalid_0's auc: 0.978645\n",
      "---- current learning rate:0.015400000000000028----\n",
      "---- current learning rate:0.015300000000000029----\n",
      "---- current learning rate:0.01520000000000003----\n",
      "---- current learning rate:0.01510000000000003----\n",
      "---- current learning rate:0.01500000000000003----\n",
      "[500]\tvalid_0's auc: 0.978729\n",
      "---- current learning rate:0.014900000000000031----\n",
      "---- current learning rate:0.014800000000000032----\n",
      "---- current learning rate:0.014700000000000032----\n",
      "---- current learning rate:0.014600000000000033----\n",
      "---- current learning rate:0.014500000000000034----\n",
      "[550]\tvalid_0's auc: 0.978769\n",
      "---- current learning rate:0.014400000000000034----\n",
      "---- current learning rate:0.014300000000000035----\n",
      "---- current learning rate:0.014200000000000036----\n",
      "---- current learning rate:0.014100000000000036----\n",
      "---- current learning rate:0.014000000000000037----\n",
      "[600]\tvalid_0's auc: 0.978805\n",
      "---- current learning rate:0.013900000000000037----\n",
      "---- current learning rate:0.013800000000000038----\n",
      "---- current learning rate:0.013700000000000039----\n",
      "---- current learning rate:0.01360000000000004----\n",
      "---- current learning rate:0.01350000000000004----\n",
      "[650]\tvalid_0's auc: 0.978839\n",
      "---- current learning rate:0.01340000000000004----\n",
      "---- current learning rate:0.013300000000000041----\n",
      "---- current learning rate:0.013200000000000042----\n",
      "---- current learning rate:0.013100000000000042----\n",
      "---- current learning rate:0.013000000000000043----\n",
      "[700]\tvalid_0's auc: 0.978873\n",
      "---- current learning rate:0.012900000000000043----\n",
      "---- current learning rate:0.012800000000000044----\n",
      "---- current learning rate:0.012700000000000045----\n",
      "---- current learning rate:0.012600000000000045----\n",
      "---- current learning rate:0.012500000000000046----\n",
      "[750]\tvalid_0's auc: 0.978887\n",
      "---- current learning rate:0.012400000000000046----\n",
      "---- current learning rate:0.012300000000000047----\n",
      "---- current learning rate:0.012200000000000048----\n",
      "---- current learning rate:0.012100000000000048----\n",
      "---- current learning rate:0.012000000000000049----\n",
      "[800]\tvalid_0's auc: 0.97888\n",
      "---- current learning rate:0.01190000000000005----\n",
      "---- current learning rate:0.01180000000000005----\n",
      "---- current learning rate:0.01170000000000005----\n",
      "---- current learning rate:0.011600000000000051----\n",
      "---- current learning rate:0.011500000000000052----\n",
      "[850]\tvalid_0's auc: 0.978905\n",
      "---- current learning rate:0.011400000000000052----\n",
      "---- current learning rate:0.011300000000000053----\n",
      "---- current learning rate:0.011200000000000054----\n",
      "---- current learning rate:0.011100000000000054----\n",
      "---- current learning rate:0.011000000000000055----\n",
      "[900]\tvalid_0's auc: 0.978912\n",
      "---- current learning rate:0.010900000000000055----\n",
      "---- current learning rate:0.010800000000000056----\n",
      "---- current learning rate:0.010700000000000057----\n",
      "---- current learning rate:0.010600000000000057----\n",
      "---- current learning rate:0.010500000000000058----\n",
      "[950]\tvalid_0's auc: 0.9789\n",
      "---- current learning rate:0.010400000000000059----\n",
      "---- current learning rate:0.010300000000000059----\n",
      "---- current learning rate:0.01020000000000006----\n",
      "---- current learning rate:0.01010000000000006----\n",
      "---- current learning rate:0.010000000000000061----\n",
      "[1000]\tvalid_0's auc: 0.978903\n",
      "---- current learning rate:0.009900000000000062----\n",
      "---- current learning rate:0.009800000000000062----\n",
      "---- current learning rate:0.009700000000000063----\n",
      "---- current learning rate:0.009600000000000063----\n",
      "---- current learning rate:0.009500000000000064----\n",
      "[1050]\tvalid_0's auc: 0.978907\n",
      "---- current learning rate:0.009400000000000065----\n",
      "---- current learning rate:0.009300000000000065----\n",
      "---- current learning rate:0.009200000000000066----\n",
      "---- current learning rate:0.009100000000000066----\n",
      "---- current learning rate:0.009000000000000067----\n",
      "[1100]\tvalid_0's auc: 0.9789\n",
      "---- current learning rate:0.008900000000000068----\n",
      "---- current learning rate:0.008800000000000068----\n",
      "---- current learning rate:0.008700000000000069----\n",
      "Early stopping, best iteration is:\n",
      "[923]\tvalid_0's auc: 0.978931\n",
      "runtime: 8656.335958719254\n"
     ]
    }
   ],
   "source": [
    "print('=============================================== training validate ===============================================')\n",
    "fea_imp_list = []\n",
    "clf = LGBMClassifier(\n",
    "    n_jobs=7,\n",
    "    learning_rate=0.02,\n",
    "    n_estimators=5000,\n",
    "    num_leaves=255,\n",
    "    subsample=0.9,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=2019,\n",
    "    metric=None,\n",
    "    \n",
    "    feature_fraction=0.8, # 随机特征采样\n",
    "    bagging_fraction=0.8, # 随机样本采样\n",
    "    bagging_freq=5       # k means perform bagging at every k iteration\n",
    ")\n",
    "\n",
    "print('************** training **************')\n",
    "clf.fit(\n",
    "    train_x, train_y,\n",
    "    eval_set=[(val_x, val_y)],\n",
    "    eval_metric='auc',\n",
    "    categorical_feature=cate_cols,\n",
    "    early_stopping_rounds=200,\n",
    "    verbose=50,\n",
    "    callbacks=[learning_rate_callback]\n",
    ")\n",
    "print('runtime:', time.time() - t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************** validate predict **************\n",
      "runtime: 17309.106901168823\n"
     ]
    }
   ],
   "source": [
    "gc.collect()\n",
    "\n",
    "print('************** validate predict **************')\n",
    "best_rounds = clf.best_iteration_\n",
    "best_auc = clf.best_score_['valid_0']['auc']\n",
    "val_pred = clf.predict_proba(val_x)[:, 1]\n",
    "fea_imp_list.append(clf.feature_importances_)\n",
    "print('runtime:', time.time() - t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print('=============================================== training predict ===============================================')\n",
    "clf = LGBMClassifier(\n",
    "    learning_rate=0.01,\n",
    "    n_estimators=best_rounds,\n",
    "    num_leaves=255,\n",
    "    subsample=0.9,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=2019\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('************** training using all the data **************')\n",
    "clf.fit(\n",
    "    train_df, labels,\n",
    "    eval_set=[(train_df, labels)],\n",
    "    categorical_feature=cate_cols,\n",
    "    verbose=50\n",
    ")\n",
    "print('runtime:', time.time() - t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************** test predict **************\n",
      "runtime: 59716.57367801666\n"
     ]
    }
   ],
   "source": [
    "print('************** test predict **************')\n",
    "# sub = pd.read_csv(path_data + 'sample.csv')\n",
    "\n",
    "sub['target'] = clf.predict_proba(test_df)[:, 1]\n",
    "fea_imp_list.append(clf.feature_importances_)\n",
    "print('runtime:', time.time() - t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================================== feat importances ===============================================\n",
      "deviceid = 70524.0\n",
      "newsid = 36244.0\n",
      "device_version = 29596.0\n",
      "lat = 13653.0\n",
      "lng = 13354.0\n",
      "lng_lat = 9820.0\n",
      "netmodel_deviceid_lng_lat_next1_exposure_ts_gap = 2935.0\n",
      "netmodel_deviceid_next1_exposure_ts_gap = 2448.0\n",
      "deviceid_next3_exposure_ts_gap = 1878.0\n",
      "netmodel_deviceid_next3_exposure_ts_gap = 1611.0\n",
      "pos_netmodel_deviceid_next1_exposure_ts_gap = 1546.0\n",
      "deviceid_lng_lat_next3_exposure_ts_gap = 1504.0\n",
      "netmodel_deviceid_lng_lat_next2_exposure_ts_gap = 1475.0\n",
      "pos_count = 1443.0\n",
      "cross_deviceid_newsid_count = 1419.0\n",
      "cross_lng_lat_pos_ent = 1401.0\n",
      "netmodel_deviceid_next2_exposure_ts_gap = 1372.0\n",
      "pos_netmodel_deviceid_lng_lat_next1_exposure_ts_gap = 1342.0\n",
      "pos = 1340.0\n",
      "deviceid_next1_exposure_ts_gap = 1209.0\n",
      "netmodel_deviceid_lng_lat_next3_exposure_ts_gap = 1183.0\n",
      "deviceid_newsid_emb_6 = 1177.0\n",
      "deviceid_next5_exposure_ts_gap = 809.0\n",
      "deviceid_lng_lat_next1_exposure_ts_gap = 805.0\n",
      "cross_deviceid_pos_ent_x = 795.0\n",
      "deviceid_next2_exposure_ts_gap = 773.0\n",
      "netmodel_deviceid_next10_exposure_ts_gap = 758.0\n",
      "netmodel_deviceid_next5_exposure_ts_gap = 691.0\n",
      "deviceid_newsid_emb_7 = 667.0\n",
      "netmodel_deviceid_lng_lat_next10_exposure_ts_gap = 652.0\n",
      "deviceid_lng_lat_next2_exposure_ts_gap = 602.0\n",
      "pos_deviceid_next1_exposure_ts_gap = 528.0\n",
      "pos_netmodel_deviceid_next2_exposure_ts_gap = 518.0\n",
      "pos_deviceid_lng_lat_next1_exposure_ts_gap = 507.0\n",
      "deviceid_lng_lat_next5_exposure_ts_gap = 488.0\n",
      "cross_netmodel_pos_count_ratio = 474.0\n",
      "deviceid_newsid_emb_2 = 470.0\n",
      "pos_netmodel_deviceid_lng_lat_next2_exposure_ts_gap = 465.0\n",
      "deviceid_newsid_emb_1 = 449.0\n",
      "cross_pos_netmodel_count = 445.0\n",
      "cross_pos_deviceid_count_ratio = 443.0\n",
      "netmodel_deviceid_lng_lat_next5_exposure_ts_gap = 426.0\n",
      "cross_pos_lng_lat_count_ratio = 402.0\n",
      "netmodel_count = 384.0\n",
      "netmodel_lng_lat_next1_exposure_ts_gap = 370.0\n",
      "cross_pos_netmodel_count_ratio = 367.0\n",
      "cross_newsid_deviceid_count_ratio = 355.0\n",
      "cross_pos_netmodel_ent = 350.0\n",
      "deviceid_next10_exposure_ts_gap = 342.0\n",
      "cross_deviceid_pos_nunique_x = 333.0\n",
      "netmodel_deviceid_prev5_exposure_ts_gap = 331.0\n",
      "cross_netmodel_lng_lat_count_ratio = 321.0\n",
      "pos_netmodel_deviceid_next3_exposure_ts_gap = 314.0\n",
      "pos_deviceid_lng_lat_next2_exposure_ts_gap = 313.0\n",
      "pos_deviceid_prev_day_ctr = 302.0\n",
      "netmodel_deviceid_prev1_exposure_ts_gap = 298.0\n",
      "cross_lng_lat_pos_nunique = 297.0\n",
      "pos_deviceid_next2_exposure_ts_gap = 269.0\n",
      "pos_netmodel_lng_lat_next1_exposure_ts_gap = 261.0\n",
      "pos_netmodel_deviceid_prev1_exposure_ts_gap = 256.0\n",
      "netmodel_deviceid_prev10_exposure_ts_gap = 254.0\n",
      "pos_newsid_next1_exposure_ts_gap = 252.0\n",
      "cross_pos_deviceid_nunique = 252.0\n",
      "deviceid_newsid_emb_3 = 242.0\n",
      "cross_pos_newsid_ent = 240.0\n",
      "lng_lat_newsid_emb_0 = 239.0\n",
      "newsid_next1_exposure_ts_gap = 231.0\n",
      "pos_deviceid_next3_exposure_ts_gap = 231.0\n",
      "deviceid_prev1_exposure_ts_gap = 224.0\n",
      "pos_newsid_prev1_exposure_ts_gap = 224.0\n",
      "deviceid_prev2_exposure_ts_gap = 222.0\n",
      "cross_deviceid_pos_ent_y = 220.0\n",
      "deviceid_lng_lat_next10_exposure_ts_gap = 206.0\n",
      "netmodel_deviceid_lng_lat_prev2_exposure_ts_gap = 200.0\n",
      "pos_netmodel_deviceid_lng_lat_next3_exposure_ts_gap = 197.0\n",
      "cross_newsid_pos_ent = 190.0\n",
      "newsid_prev1_exposure_ts_gap = 189.0\n",
      "lng_lat_next3_exposure_ts_gap = 188.0\n",
      "newsid_deviceid_emb_1 = 185.0\n",
      "cross_deviceid_netmodel_count_ratio = 178.0\n",
      "cross_netmodel_deviceid_count_ratio = 177.0\n",
      "cross_lng_lat_pos_count_ratio = 177.0\n",
      "newsid_lng_lat_emb_6 = 173.0\n",
      "deviceid_prev5_exposure_ts_gap = 171.0\n",
      "netmodel_deviceid_prev2_exposure_ts_gap = 171.0\n",
      "netmodel_deviceid_lng_lat_prev1_exposure_ts_gap = 169.0\n",
      "newsid_deviceid_emb_5 = 169.0\n",
      "pos_deviceid_prev1_exposure_ts_gap = 167.0\n",
      "netmodel_lng_lat_next2_exposure_ts_gap = 164.0\n",
      "deviceid_lng_lat_prev1_exposure_ts_gap = 160.0\n",
      "lng_lat_next1_exposure_ts_gap = 159.0\n",
      "netmodel_deviceid_prev3_exposure_ts_gap = 157.0\n",
      "cross_netmodel_deviceid_ent = 154.0\n",
      "lng_lat_newsid_emb_2 = 152.0\n",
      "netmodel_lng_lat_next3_exposure_ts_gap = 147.0\n",
      "newsid_lng_lat_emb_7 = 147.0\n",
      "newsid_lng_lat_emb_3 = 144.0\n",
      "cross_deviceid_pos_count_ratio = 142.0\n",
      "cross_netmodel_newsid_count_ratio = 142.0\n",
      "newsid_deviceid_emb_7 = 138.0\n",
      "cross_deviceid_newsid_count_ratio = 134.0\n",
      "cross_newsid_netmodel_count_ratio = 132.0\n",
      "cross_pos_deviceid_ent = 128.0\n",
      "cross_deviceid_pos_nunique_ratio_deviceid_count = 125.0\n",
      "netmodel_lng_lat_next10_exposure_ts_gap = 123.0\n",
      "deviceid_newsid_emb_0 = 123.0\n",
      "newsid_lng_lat_emb_4 = 122.0\n",
      "netmodel_deviceid_lng_lat_prev3_exposure_ts_gap = 117.0\n",
      "newsid_deviceid_emb_2 = 117.0\n",
      "cross_pos_lng_lat_nunique_ratio_pos_count = 116.0\n",
      "deviceid_prev10_exposure_ts_gap = 115.0\n",
      "pos_lng_lat_next1_exposure_ts_gap = 115.0\n",
      "deviceid_newsid_emb_5 = 115.0\n",
      "pos_netmodel_deviceid_next5_exposure_ts_gap = 111.0\n",
      "cross_newsid_lng_lat_count = 110.0\n",
      "lng_lat_next5_exposure_ts_gap = 108.0\n",
      "netmodel_lng_lat_next5_exposure_ts_gap = 107.0\n",
      "newsid_deviceid_emb_3 = 105.0\n",
      "deviceid_prev3_exposure_ts_gap = 104.0\n",
      "cross_newsid_pos_count_ratio = 102.0\n",
      "newsid_deviceid_emb_0 = 101.0\n",
      "deviceid_lng_lat_prev2_exposure_ts_gap = 100.0\n",
      "pos_netmodel_deviceid_lng_lat_prev1_exposure_ts_gap = 98.0\n",
      "cross_newsid_netmodel_count = 98.0\n",
      "cross_lng_lat_netmodel_count_ratio = 96.0\n",
      "pos_deviceid_lng_lat_prev1_exposure_ts_gap = 93.0\n",
      "cross_lng_lat_netmodel_ent = 93.0\n",
      "deviceid_newsid_emb_4 = 92.0\n",
      "newsid_lng_lat_emb_5 = 92.0\n",
      "newsid_prev10_exposure_ts_gap = 91.0\n",
      "newsid_deviceid_emb_6 = 91.0\n",
      "lng_lat_next2_exposure_ts_gap = 90.0\n",
      "cross_deviceid_netmodel_count = 90.0\n",
      "newsid_lng_lat_emb_2 = 90.0\n",
      "newsid_next5_exposure_ts_gap = 89.0\n",
      "pos_deviceid_next5_exposure_ts_gap = 89.0\n",
      "lng_lat_newsid_emb_7 = 87.0\n",
      "newsid_next10_exposure_ts_gap = 86.0\n",
      "pos_deviceid_prev2_exposure_ts_gap = 85.0\n",
      "pos_netmodel_lng_lat_next2_exposure_ts_gap = 84.0\n",
      "newsid_next3_exposure_ts_gap = 83.0\n",
      "pos_netmodel_deviceid_prev5_exposure_ts_gap = 83.0\n",
      "newsid_lng_lat_emb_1 = 83.0\n",
      "newsid_prev3_exposure_ts_gap = 82.0\n",
      "netmodel_deviceid_lng_lat_prev5_exposure_ts_gap = 82.0\n",
      "cross_newsid_netmodel_ent = 81.0\n",
      "pos_netmodel_deviceid_prev2_exposure_ts_gap = 80.0\n",
      "pos_netmodel_deviceid_prev3_exposure_ts_gap = 80.0\n",
      "pos_netmodel_deviceid_lng_lat_prev2_exposure_ts_gap = 80.0\n",
      "newsid_deviceid_emb_4 = 80.0\n",
      "cross_newsid_lng_lat_count_ratio = 79.0\n",
      "pos_deviceid_lng_lat_next3_exposure_ts_gap = 78.0\n",
      "pos_netmodel_deviceid_prev10_exposure_ts_gap = 77.0\n",
      "cross_deviceid_netmodel_nunique_ratio_deviceid_count = 77.0\n",
      "cross_newsid_netmodel_nunique_ratio_newsid_count = 77.0\n",
      "pos_deviceid_prev5_exposure_ts_gap = 75.0\n",
      "cross_deviceid_pos_count = 75.0\n",
      "pos_newsid_next10_exposure_ts_gap = 73.0\n",
      "pos_deviceid_next10_exposure_ts_gap = 72.0\n",
      "pos_netmodel_deviceid_lng_lat_next5_exposure_ts_gap = 72.0\n",
      "pos_deviceid_lng_lat_next5_exposure_ts_gap = 71.0\n",
      "pos_lng_lat_next2_exposure_ts_gap = 69.0\n",
      "cross_newsid_pos_count = 69.0\n",
      "cross_newsid_pos_nunique_ratio_newsid_count = 69.0\n",
      "cross_netmodel_lng_lat_count = 69.0\n",
      "pos_netmodel_deviceid_next10_exposure_ts_gap = 67.0\n",
      "cross_newsid_lng_lat_nunique_ratio_newsid_count = 67.0\n",
      "cross_lng_lat_pos_nunique_ratio_lng_lat_count = 67.0\n",
      "deviceid_count = 66.0\n",
      "newsid_prev5_exposure_ts_gap = 66.0\n",
      "pos_deviceid_prev3_exposure_ts_gap = 66.0\n",
      "lng_lat_next10_exposure_ts_gap = 65.0\n",
      "device_version_count = 63.0\n",
      "newsid_lng_lat_emb_0 = 62.0\n",
      "deviceid_prev_day_ctr = 61.0\n",
      "pos_deviceid_prev10_exposure_ts_gap = 61.0\n",
      "cross_deviceid_lng_lat_count = 61.0\n",
      "newsid_prev2_exposure_ts_gap = 60.0\n",
      "cross_deviceid_lng_lat_nunique_ratio_deviceid_count = 60.0\n",
      "lng_lat_newsid_emb_6 = 60.0\n",
      "newsid_count = 57.0\n",
      "newsid_next2_exposure_ts_gap = 57.0\n",
      "pos_lng_lat_next3_exposure_ts_gap = 57.0\n",
      "lng_lat_newsid_emb_5 = 57.0\n",
      "pos_newsid_prev10_exposure_ts_gap = 56.0\n",
      "pos_netmodel_lng_lat_next3_exposure_ts_gap = 56.0\n",
      "cross_deviceid_newsid_ent_x = 56.0\n",
      "deviceid_prev_day_count = 55.0\n",
      "netmodel_deviceid_lng_lat_prev10_exposure_ts_gap = 55.0\n",
      "deviceid_lng_lat_prev3_exposure_ts_gap = 52.0\n",
      "pos_netmodel_deviceid_lng_lat_prev3_exposure_ts_gap = 51.0\n",
      "lng_lat_newsid_emb_3 = 51.0\n",
      "pos_newsid_next5_exposure_ts_gap = 50.0\n",
      "netmodel_lng_lat_prev2_exposure_ts_gap = 50.0\n",
      "pos_newsid_next3_exposure_ts_gap = 49.0\n",
      "pos_newsid_prev5_exposure_ts_gap = 49.0\n",
      "cross_deviceid_newsid_nunique_ratio_deviceid_count = 48.0\n",
      "cross_pos_newsid_count_ratio = 48.0\n",
      "cross_deviceid_newsid_nunique_x = 47.0\n",
      "cross_newsid_deviceid_nunique_ratio_newsid_count = 47.0\n",
      "pos_deviceid_prev_day_count = 45.0\n",
      "cross_deviceid_pos_nunique_y = 45.0\n",
      "cross_newsid_lng_lat_ent = 45.0\n",
      "cross_lng_lat_newsid_nunique = 45.0\n",
      "pos_deviceid_prev_day_click_count = 43.0\n",
      "lng_lat_newsid_emb_4 = 43.0\n",
      "pos_newsid_next2_exposure_ts_gap = 42.0\n",
      "pos_netmodel_lng_lat_next5_exposure_ts_gap = 42.0\n",
      "cross_deviceid_netmodel_ent = 42.0\n",
      "pos_newsid_prev3_exposure_ts_gap = 41.0\n",
      "deviceid_lng_lat_prev5_exposure_ts_gap = 41.0\n",
      "pos_newsid_prev2_exposure_ts_gap = 40.0\n",
      "pos_deviceid_lng_lat_prev10_exposure_ts_gap = 40.0\n",
      "netmodel_lng_lat_prev5_exposure_ts_gap = 40.0\n",
      "lng_lat_prev1_exposure_ts_gap = 39.0\n",
      "pos_deviceid_lng_lat_prev3_exposure_ts_gap = 39.0\n",
      "cross_lng_lat_newsid_count_ratio = 39.0\n",
      "deviceid_prev_day_click_count = 38.0\n",
      "pos_lng_lat_next5_exposure_ts_gap = 38.0\n",
      "lng_lat_newsid_emb_1 = 38.0\n",
      "netmodel_lng_lat_prev3_exposure_ts_gap = 37.0\n",
      "netmodel_lng_lat_prev1_exposure_ts_gap = 36.0\n",
      "pos_netmodel_deviceid_lng_lat_next10_exposure_ts_gap = 36.0\n",
      "cross_newsid_deviceid_ent = 36.0\n",
      "pos_netmodel_lng_lat_prev1_exposure_ts_gap = 35.0\n",
      "deviceid_lng_lat_emb_3 = 35.0\n",
      "cross_pos_deviceid_nunique_ratio_pos_count = 34.0\n",
      "lng_lat_deviceid_emb_3 = 34.0\n",
      "pos_deviceid_lng_lat_next10_exposure_ts_gap = 33.0\n",
      "deviceid_lng_lat_emb_0 = 33.0\n",
      "pos_deviceid_lng_lat_prev2_exposure_ts_gap = 32.0\n",
      "pos_netmodel_deviceid_lng_lat_prev5_exposure_ts_gap = 32.0\n",
      "cross_newsid_deviceid_nunique = 32.0\n",
      "cross_lng_lat_newsid_nunique_ratio_lng_lat_count = 32.0\n",
      "deviceid_lng_lat_emb_6 = 32.0\n",
      "pos_netmodel_lng_lat_next10_exposure_ts_gap = 31.0\n",
      "cross_deviceid_pos_ent = 31.0\n",
      "cross_lng_lat_deviceid_nunique_ratio_lng_lat_count = 31.0\n",
      "lng_lat_deviceid_emb_0 = 31.0\n",
      "lat_count = 30.0\n",
      "pos_lng_lat_prev1_exposure_ts_gap = 30.0\n",
      "pos_lng_lat_next10_exposure_ts_gap = 30.0\n",
      "lng_lat_deviceid_emb_4 = 30.0\n",
      "lng_lat_prev2_exposure_ts_gap = 29.0\n",
      "cross_newsid_lng_lat_nunique = 29.0\n",
      "deviceid_lng_lat_emb_2 = 29.0\n",
      "netmodel_lng_lat_prev10_exposure_ts_gap = 28.0\n",
      "minute = 27.0\n",
      "deviceid_lng_lat_prev10_exposure_ts_gap = 27.0\n",
      "lng_lat_deviceid_emb_7 = 27.0\n",
      "pos_lng_lat_prev3_exposure_ts_gap = 26.0\n",
      "pos_lng_lat_prev5_exposure_ts_gap = 26.0\n",
      "pos_netmodel_lng_lat_prev10_exposure_ts_gap = 26.0\n",
      "lng_lat_deviceid_emb_5 = 26.0\n",
      "pos_netmodel_lng_lat_prev3_exposure_ts_gap = 25.0\n",
      "cross_pos_lng_lat_count = 25.0\n",
      "device_vendor = 24.0\n",
      "device_vendor_count = 24.0\n",
      "pos_lng_lat_prev10_exposure_ts_gap = 24.0\n",
      "pos_deviceid_lng_lat_prev5_exposure_ts_gap = 24.0\n",
      "pos_netmodel_lng_lat_prev2_exposure_ts_gap = 24.0\n",
      "cross_netmodel_deviceid_nunique = 24.0\n",
      "cross_lng_lat_newsid_ent = 24.0\n",
      "lng_lat_deviceid_emb_2 = 24.0\n",
      "lng_count = 23.0\n",
      "pos_lng_lat_prev2_exposure_ts_gap = 23.0\n",
      "deviceid_lng_lat_emb_1 = 23.0\n",
      "lng_lat_prev10_exposure_ts_gap = 22.0\n",
      "cross_lng_lat_deviceid_count_ratio = 22.0\n",
      "cross_deviceid_lng_lat_count_ratio = 22.0\n",
      "deviceid_lng_lat_emb_7 = 22.0\n",
      "lng_lat_prev5_exposure_ts_gap = 21.0\n",
      "pos_netmodel_deviceid_lng_lat_prev10_exposure_ts_gap = 21.0\n",
      "cross_deviceid_lng_lat_ent = 21.0\n",
      "cross_newsid_pos_nunique = 21.0\n",
      "lng_lat_deviceid_emb_1 = 21.0\n",
      "lng_lat_deviceid_emb_6 = 21.0\n",
      "hour = 20.0\n",
      "deviceid_lng_lat_emb_4 = 20.0\n",
      "deviceid_lng_lat_emb_5 = 20.0\n",
      "app_version = 19.0\n",
      "pos_netmodel_lng_lat_prev5_exposure_ts_gap = 19.0\n",
      "app_version_count = 18.0\n",
      "cross_deviceid_lng_lat_nunique = 18.0\n",
      "cross_netmodel_deviceid_nunique_ratio_netmodel_count = 18.0\n",
      "lng_lat_prev3_exposure_ts_gap = 16.0\n",
      "cross_lng_lat_netmodel_nunique_ratio_lng_lat_count = 15.0\n",
      "cross_pos_lng_lat_ent = 14.0\n",
      "osversion_count = 11.0\n",
      "cross_pos_newsid_nunique = 11.0\n",
      "netmodel = 10.0\n",
      "cross_pos_newsid_nunique_ratio_pos_count = 10.0\n",
      "cross_deviceid_newsid_ent_y = 9.0\n",
      "lng_lat_count = 7.0\n",
      "cross_deviceid_netmodel_nunique = 7.0\n",
      "cross_deviceid_pos_nunique = 7.0\n",
      "cross_netmodel_newsid_nunique_ratio_netmodel_count = 7.0\n",
      "cross_netmodel_lng_lat_ent = 7.0\n",
      "osversion = 5.0\n",
      "cross_deviceid_newsid_nunique_y = 5.0\n",
      "cross_newsid_netmodel_nunique = 5.0\n",
      "cross_lng_lat_netmodel_nunique = 5.0\n",
      "cross_deviceid_newsid_ent = 3.0\n",
      "cross_netmodel_lng_lat_nunique_ratio_netmodel_count = 3.0\n",
      "cross_deviceid_newsid_nunique = 2.0\n",
      "cross_pos_netmodel_nunique = 0.0\n",
      "cross_pos_netmodel_nunique_ratio_pos_count = 0.0\n",
      "cross_pos_lng_lat_nunique = 0.0\n",
      "cross_netmodel_newsid_nunique = 0.0\n",
      "cross_netmodel_newsid_ent = 0.0\n",
      "cross_netmodel_pos_nunique = 0.0\n",
      "cross_netmodel_pos_ent = 0.0\n",
      "cross_netmodel_pos_nunique_ratio_netmodel_count = 0.0\n",
      "cross_netmodel_lng_lat_nunique = 0.0\n",
      "cross_lng_lat_deviceid_nunique = 0.0\n",
      "cross_lng_lat_deviceid_ent = 0.0\n"
     ]
    }
   ],
   "source": [
    "print('=============================================== feat importances ===============================================')\n",
    "# 特征重要性可以好好看看\n",
    "fea_imp_dict = dict(zip(train_df.columns.values, np.mean(fea_imp_list, axis=0)))\n",
    "fea_imp_item = sorted(fea_imp_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "for f, imp in fea_imp_item:\n",
    "    print('{} = {}'.format(f, imp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================================== threshold search ===============================================\n",
      "step: 0   best threshold: 0.05   best f1: 0.6850870278409747\n",
      "step: 1   best threshold: 0.052000000000000005   best f1: 0.6882450875517184\n",
      "step: 2   best threshold: 0.054000000000000006   best f1: 0.6910326188891379\n",
      "step: 3   best threshold: 0.056   best f1: 0.6938570740696238\n",
      "step: 4   best threshold: 0.058   best f1: 0.6965791884245541\n",
      "step: 5   best threshold: 0.060000000000000005   best f1: 0.6992329151704849\n",
      "step: 6   best threshold: 0.062   best f1: 0.7017197687029522\n",
      "step: 7   best threshold: 0.064   best f1: 0.7041769142885771\n",
      "step: 8   best threshold: 0.066   best f1: 0.7064632263468276\n",
      "step: 9   best threshold: 0.068   best f1: 0.7087193458030819\n",
      "step: 10   best threshold: 0.07   best f1: 0.7108921822890651\n",
      "step: 11   best threshold: 0.07200000000000001   best f1: 0.7129447063085894\n",
      "step: 12   best threshold: 0.07400000000000001   best f1: 0.7149704145256728\n",
      "step: 13   best threshold: 0.07600000000000001   best f1: 0.7168875114000658\n",
      "step: 14   best threshold: 0.078   best f1: 0.7187499424441616\n",
      "step: 15   best threshold: 0.08   best f1: 0.7206061653680799\n",
      "step: 16   best threshold: 0.082   best f1: 0.7224066366944185\n",
      "step: 17   best threshold: 0.084   best f1: 0.7241377705159179\n",
      "step: 18   best threshold: 0.08600000000000001   best f1: 0.7258291609402343\n",
      "step: 19   best threshold: 0.088   best f1: 0.7275195419065851\n",
      "step: 20   best threshold: 0.09   best f1: 0.7290782169669175\n",
      "step: 21   best threshold: 0.092   best f1: 0.7305726858945811\n",
      "step: 22   best threshold: 0.094   best f1: 0.7320326763794753\n",
      "step: 23   best threshold: 0.096   best f1: 0.7334158679041789\n",
      "step: 24   best threshold: 0.098   best f1: 0.7347812134272516\n",
      "step: 25   best threshold: 0.1   best f1: 0.7361417374720542\n",
      "step: 26   best threshold: 0.10200000000000001   best f1: 0.7375042740281795\n",
      "step: 27   best threshold: 0.10400000000000001   best f1: 0.7388307701764564\n",
      "step: 28   best threshold: 0.10600000000000001   best f1: 0.74009463992811\n",
      "step: 29   best threshold: 0.10800000000000001   best f1: 0.7413521184979723\n",
      "step: 30   best threshold: 0.11   best f1: 0.7425754846706564\n",
      "step: 31   best threshold: 0.112   best f1: 0.7437048255641798\n",
      "step: 32   best threshold: 0.114   best f1: 0.7449075732328345\n",
      "step: 33   best threshold: 0.116   best f1: 0.7461302001502835\n",
      "step: 34   best threshold: 0.11800000000000001   best f1: 0.7471965624993885\n",
      "step: 35   best threshold: 0.12000000000000001   best f1: 0.7482277572252974\n",
      "step: 36   best threshold: 0.12200000000000001   best f1: 0.7493223080364384\n",
      "step: 37   best threshold: 0.124   best f1: 0.7503619364115421\n",
      "step: 38   best threshold: 0.126   best f1: 0.7513459369005024\n",
      "step: 39   best threshold: 0.128   best f1: 0.7522737758838172\n",
      "step: 40   best threshold: 0.13   best f1: 0.7532459799271756\n",
      "step: 41   best threshold: 0.132   best f1: 0.7541787474450086\n",
      "step: 42   best threshold: 0.134   best f1: 0.7550400733681566\n",
      "step: 43   best threshold: 0.136   best f1: 0.7560024297451964\n",
      "step: 44   best threshold: 0.138   best f1: 0.7568638522469706\n",
      "step: 45   best threshold: 0.14   best f1: 0.7577804644349574\n",
      "step: 46   best threshold: 0.14200000000000002   best f1: 0.7586052969439471\n",
      "step: 47   best threshold: 0.14400000000000002   best f1: 0.7594222523132476\n",
      "step: 48   best threshold: 0.14600000000000002   best f1: 0.7602876088326037\n",
      "step: 49   best threshold: 0.14800000000000002   best f1: 0.7611677278511874\n",
      "step: 50   best threshold: 0.15000000000000002   best f1: 0.7619628780038336\n",
      "step: 51   best threshold: 0.15200000000000002   best f1: 0.7627624760554397\n",
      "step: 52   best threshold: 0.15400000000000003   best f1: 0.7635100687600298\n",
      "step: 53   best threshold: 0.156   best f1: 0.7642842577487766\n",
      "step: 54   best threshold: 0.158   best f1: 0.7649808937106038\n",
      "step: 55   best threshold: 0.16   best f1: 0.7657131044702193\n",
      "step: 56   best threshold: 0.162   best f1: 0.766460521405342\n",
      "step: 57   best threshold: 0.164   best f1: 0.767142255503169\n",
      "step: 58   best threshold: 0.166   best f1: 0.7678644750125289\n",
      "step: 59   best threshold: 0.168   best f1: 0.7684615408405954\n",
      "step: 60   best threshold: 0.16999999999999998   best f1: 0.7691456083478002\n",
      "step: 61   best threshold: 0.172   best f1: 0.7696856034235743\n",
      "step: 62   best threshold: 0.174   best f1: 0.7702676376839828\n",
      "step: 63   best threshold: 0.176   best f1: 0.7708812340078786\n",
      "step: 64   best threshold: 0.178   best f1: 0.7714425635314998\n",
      "step: 65   best threshold: 0.18   best f1: 0.7719771520943914\n",
      "step: 66   best threshold: 0.182   best f1: 0.7725986578525641\n",
      "step: 67   best threshold: 0.184   best f1: 0.773172421649087\n",
      "step: 68   best threshold: 0.186   best f1: 0.7736911470213538\n",
      "step: 69   best threshold: 0.188   best f1: 0.7742702616551572\n",
      "step: 70   best threshold: 0.19   best f1: 0.7747538270235754\n",
      "step: 71   best threshold: 0.192   best f1: 0.775258608175742\n",
      "step: 72   best threshold: 0.194   best f1: 0.7758170898746181\n",
      "step: 73   best threshold: 0.196   best f1: 0.7763390341351603\n",
      "step: 74   best threshold: 0.198   best f1: 0.7768027583349366\n",
      "step: 75   best threshold: 0.2   best f1: 0.7772296199996188\n",
      "step: 76   best threshold: 0.202   best f1: 0.7777073224525805\n",
      "step: 77   best threshold: 0.20400000000000001   best f1: 0.7782040008326218\n",
      "step: 78   best threshold: 0.20600000000000002   best f1: 0.7787298676599791\n",
      "step: 79   best threshold: 0.20800000000000002   best f1: 0.7791365297144135\n",
      "step: 80   best threshold: 0.21000000000000002   best f1: 0.7795475277260628\n",
      "step: 81   best threshold: 0.21200000000000002   best f1: 0.7800182720613771\n",
      "step: 82   best threshold: 0.21400000000000002   best f1: 0.7804269381081\n",
      "step: 83   best threshold: 0.21600000000000003   best f1: 0.7807975033410605\n",
      "step: 84   best threshold: 0.21800000000000003   best f1: 0.7812138079970976\n",
      "step: 85   best threshold: 0.22000000000000003   best f1: 0.7815661030575909\n",
      "step: 86   best threshold: 0.22200000000000003   best f1: 0.7819748448659092\n",
      "step: 87   best threshold: 0.22400000000000003   best f1: 0.7823388460663705\n",
      "step: 88   best threshold: 0.22599999999999998   best f1: 0.7827038766986801\n",
      "step: 89   best threshold: 0.22799999999999998   best f1: 0.783097562372922\n",
      "step: 90   best threshold: 0.22999999999999998   best f1: 0.7834003911979381\n",
      "step: 91   best threshold: 0.23199999999999998   best f1: 0.7837776313165037\n",
      "step: 92   best threshold: 0.23399999999999999   best f1: 0.7840936104161126\n",
      "step: 93   best threshold: 0.236   best f1: 0.7844154319571908\n",
      "step: 94   best threshold: 0.238   best f1: 0.7847445432647566\n",
      "step: 95   best threshold: 0.24   best f1: 0.785015051213361\n",
      "step: 96   best threshold: 0.242   best f1: 0.785357192356004\n",
      "step: 97   best threshold: 0.244   best f1: 0.7856266249058798\n",
      "step: 98   best threshold: 0.246   best f1: 0.7859799112663693\n",
      "step: 99   best threshold: 0.248   best f1: 0.7863243554817203\n",
      "step: 100   best threshold: 0.25   best f1: 0.7866161588450504\n",
      "step: 101   best threshold: 0.252   best f1: 0.7868922709756957\n",
      "step: 102   best threshold: 0.254   best f1: 0.7871937332907926\n",
      "step: 103   best threshold: 0.256   best f1: 0.7874196515618029\n",
      "step: 104   best threshold: 0.258   best f1: 0.7876714292962382\n",
      "step: 105   best threshold: 0.26   best f1: 0.7878957220875462\n",
      "step: 106   best threshold: 0.262   best f1: 0.7881651491796282\n",
      "step: 107   best threshold: 0.264   best f1: 0.7885102345186781\n",
      "step: 108   best threshold: 0.266   best f1: 0.7888167427360822\n",
      "step: 109   best threshold: 0.268   best f1: 0.7890734085273675\n",
      "step: 110   best threshold: 0.27   best f1: 0.7892688119708551\n",
      "step: 111   best threshold: 0.272   best f1: 0.7895286676642544\n",
      "step: 112   best threshold: 0.274   best f1: 0.789807597401657\n",
      "step: 113   best threshold: 0.276   best f1: 0.7900113102235944\n",
      "step: 114   best threshold: 0.278   best f1: 0.7902252926861684\n",
      "step: 115   best threshold: 0.28   best f1: 0.7903752787027492\n",
      "step: 116   best threshold: 0.28200000000000003   best f1: 0.7905996254090442\n",
      "step: 117   best threshold: 0.28400000000000003   best f1: 0.7907585150944177\n",
      "step: 118   best threshold: 0.28600000000000003   best f1: 0.7909405436706239\n",
      "step: 119   best threshold: 0.28800000000000003   best f1: 0.7911698975619129\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 120   best threshold: 0.29   best f1: 0.7913279925479507\n",
      "step: 121   best threshold: 0.292   best f1: 0.7914948064615682\n",
      "step: 122   best threshold: 0.294   best f1: 0.7916540739504441\n",
      "step: 123   best threshold: 0.296   best f1: 0.7917970672844609\n",
      "step: 124   best threshold: 0.298   best f1: 0.791994176596519\n",
      "step: 125   best threshold: 0.3   best f1: 0.7921960339609915\n",
      "step: 126   best threshold: 0.302   best f1: 0.7923730493866467\n",
      "step: 127   best threshold: 0.304   best f1: 0.7925262394920093\n",
      "step: 128   best threshold: 0.306   best f1: 0.7926335835819354\n",
      "step: 129   best threshold: 0.308   best f1: 0.7928203868814138\n",
      "step: 130   best threshold: 0.31   best f1: 0.7929373412131091\n",
      "step: 131   best threshold: 0.312   best f1: 0.7931287157823242\n",
      "step: 132   best threshold: 0.314   best f1: 0.7932800529381229\n",
      "step: 133   best threshold: 0.316   best f1: 0.7933625655182811\n",
      "step: 134   best threshold: 0.318   best f1: 0.7935287855381072\n",
      "step: 135   best threshold: 0.32   best f1: 0.7936667487134867\n",
      "step: 136   best threshold: 0.322   best f1: 0.7937572564386746\n",
      "step: 137   best threshold: 0.324   best f1: 0.7939013280032678\n",
      "step: 138   best threshold: 0.326   best f1: 0.7940623424180919\n",
      "step: 139   best threshold: 0.328   best f1: 0.7941851533285191\n",
      "step: 140   best threshold: 0.33   best f1: 0.7942940557516479\n",
      "step: 141   best threshold: 0.332   best f1: 0.7944202278841077\n",
      "step: 142   best threshold: 0.334   best f1: 0.7945053436294683\n",
      "step: 143   best threshold: 0.336   best f1: 0.7945573831084828\n",
      "step: 144   best threshold: 0.338   best f1: 0.7946637125981156\n",
      "step: 145   best threshold: 0.33999999999999997   best f1: 0.7947614328844765\n",
      "step: 146   best threshold: 0.34199999999999997   best f1: 0.7948401780975272\n",
      "step: 147   best threshold: 0.344   best f1: 0.7949245374737078\n",
      "step: 148   best threshold: 0.346   best f1: 0.7950289205324165\n",
      "step: 149   best threshold: 0.348   best f1: 0.7951750913042114\n",
      "step: 150   best threshold: 0.35   best f1: 0.7951963459264156\n",
      "step: 151   best threshold: 0.352   best f1: 0.7952118331529167\n",
      "step: 154   best threshold: 0.358   best f1: 0.7952505189923132\n",
      "step: 157   best threshold: 0.364   best f1: 0.7952899952857736\n",
      "step: 158   best threshold: 0.366   best f1: 0.7953052161265216\n",
      "step: 159   best threshold: 0.368   best f1: 0.7953332651749381\n",
      "step: 160   best threshold: 0.37   best f1: 0.7953752792229866\n",
      "step: 161   best threshold: 0.372   best f1: 0.7953930735961321\n",
      "step: 162   best threshold: 0.374   best f1: 0.7954098592545442\n",
      "step: 163   best threshold: 0.376   best f1: 0.7954555377373742\n",
      "step: 164   best threshold: 0.378   best f1: 0.7955279150941725\n",
      "step: 165   best threshold: 0.38   best f1: 0.7955434995967771\n",
      "step: 166   best threshold: 0.382   best f1: 0.7955596801151511\n",
      "step: 167   best threshold: 0.384   best f1: 0.795602905959207\n",
      "search finish.\n",
      "\n",
      "best auc: 0.9789307282567236\n",
      "best f1: 0.795602905959207\n",
      "validate mean: 0.10763043665548372\n",
      "runtime: 60441.84958791733\n"
     ]
    }
   ],
   "source": [
    "print('=============================================== threshold search ===============================================')\n",
    "# f1阈值敏感，所以对阈值做一个简单的迭代搜索。\n",
    "t0 = 0.05\n",
    "v = 0.002\n",
    "best_t = t0\n",
    "best_f1 = 0\n",
    "for step in range(201):\n",
    "    curr_t = t0 + step * v\n",
    "    y = [1 if x >= curr_t else 0 for x in val_pred]\n",
    "    curr_f1 = f1_score(val_y, y)\n",
    "    if curr_f1 > best_f1:\n",
    "        best_t = curr_t\n",
    "        best_f1 = curr_f1\n",
    "        print('step: {}   best threshold: {}   best f1: {}'.format(step, best_t, best_f1))\n",
    "print('search finish.')\n",
    "\n",
    "val_pred = [1 if x >= best_t else 0 for x in val_pred]\n",
    "print('\\nbest auc:', best_auc)\n",
    "print('best f1:', f1_score(val_y, val_pred))\n",
    "print('validate mean:', np.mean(val_pred))\n",
    "print('runtime:', time.time() - t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================================== sub save ===============================================\n",
      "runtime: 60467.53868508339\n",
      "finish.\n",
      "========================================================================================================\n"
     ]
    }
   ],
   "source": [
    "print('=============================================== sub save ===============================================')\n",
    "sub.to_csv('sub_prob_{}_{}_{}.csv'.format(best_auc, best_f1, sub['target'].mean()), index=False)\n",
    "sub['target'] = sub['target'].apply(lambda x: 1 if x >= best_t else 0)\n",
    "sub.to_csv('sub_{}_{}_{}.csv'.format(best_auc, best_f1, sub['target'].mean()), index=False)\n",
    "print('runtime:', time.time() - t)\n",
    "print('finish.')\n",
    "print('========================================================================================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
