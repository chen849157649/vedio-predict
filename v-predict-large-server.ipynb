{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total cpu count 40\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'vaex' has no attribute 'settings'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-093addeaf340>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'NUMEXPR_MAX_THREADS'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'10'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtimeit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_mem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/ryan/tmp/core/utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mvaex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/wanghuibo/apps/anaconda3/lib/python3.7/site-packages/vaex/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 538\u001b[0;31m \u001b[0maliases\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvaex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_store_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"aliases\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m \u001b[0;31m# py2/p3 compatibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'vaex' has no attribute 'settings'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from lightgbm.sklearn import LGBMClassifier\n",
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "from scipy.stats import entropy\n",
    "from gensim.models import Word2Vec\n",
    "import time\n",
    "import gc\n",
    "import os\n",
    "\n",
    "import tqdm                                                                                                   \n",
    "import concurrent.futures\n",
    "import multiprocessing\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "num_processes = multiprocessing.cpu_count()\n",
    "print(\"total cpu count\", +num_processes) \n",
    "\n",
    "os.environ['NUMEXPR_MAX_THREADS'] = '10'\n",
    "\n",
    "from core.utils import timeit, reduce_mem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/home/iflow/ryan/tmp/\"\n",
    "path_sub = path + 'sub/'\n",
    "path_npy = path + 'npy/'\n",
    "path_data = path + 'raw/'\n",
    "path_model = path + 'model/'\n",
    "path_result = path + 'result/'\n",
    "path_pickle = path + 'pickle/'\n",
    "path_profile = path + 'profile/'\n",
    "\n",
    "debug_small = False\n",
    "\n",
    "if debug_small:\n",
    "    train_df = pd.read_pickle(path_pickle + 'train_small.pickle')\n",
    "    test_df = pd.read_pickle(path_pickle + 'test_small.pickle')\n",
    "    # app = pd.read_pickle(path_pickle + 'app_small.pickle')\n",
    "    # user = pd.read_pickle(path_pickle + 'user_small.pickle')\n",
    "else:\n",
    "    train_df = pd.read_pickle(path_pickle + 'train.pickle')\n",
    "    test_df = pd.read_pickle(path_pickle + 'test.pickle')\n",
    "    # app = pd.read_pickle(path_pickle + 'app.pickle')\n",
    "    # user = pd.read_pickle(path_pickle + 'user.pickle')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>deviceid</th>\n",
       "      <th>newsid</th>\n",
       "      <th>guid</th>\n",
       "      <th>pos</th>\n",
       "      <th>app_version</th>\n",
       "      <th>device_vendor</th>\n",
       "      <th>netmodel</th>\n",
       "      <th>osversion</th>\n",
       "      <th>lng</th>\n",
       "      <th>lat</th>\n",
       "      <th>device_version</th>\n",
       "      <th>ts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8b2d7f2aed47ab32e9c6ae4f5ae00147</td>\n",
       "      <td>8008333091915950969</td>\n",
       "      <td>9a2c909ebc47aec49d9c160cdb4a6572</td>\n",
       "      <td>1</td>\n",
       "      <td>2.1.5</td>\n",
       "      <td>HONOR</td>\n",
       "      <td>g4</td>\n",
       "      <td>9</td>\n",
       "      <td>1.125385e+02</td>\n",
       "      <td>3.783793e+01</td>\n",
       "      <td>STF-AL00</td>\n",
       "      <td>1573298086436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8b2d7f2aed47ab32e9c6ae4f5ae00147</td>\n",
       "      <td>8008333091915950969</td>\n",
       "      <td>9a2c909ebc47aec49d9c160cdb4a6572</td>\n",
       "      <td>1</td>\n",
       "      <td>2.1.5</td>\n",
       "      <td>HONOR</td>\n",
       "      <td>w</td>\n",
       "      <td>9</td>\n",
       "      <td>1.117312e+02</td>\n",
       "      <td>3.562274e+01</td>\n",
       "      <td>STF-AL00</td>\n",
       "      <td>1573298087570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>832aaa33cdf4a0938ba2c795eb3ffefd</td>\n",
       "      <td>4941885624885390992</td>\n",
       "      <td>d51a157d2b1e0e9aed4dd7f9900b85b2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.9.9</td>\n",
       "      <td>vivo</td>\n",
       "      <td>w</td>\n",
       "      <td>8.1.0</td>\n",
       "      <td>4.940656e-324</td>\n",
       "      <td>4.940656e-324</td>\n",
       "      <td>V1818T</td>\n",
       "      <td>1573377075934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>832aaa33cdf4a0938ba2c795eb3ffefd</td>\n",
       "      <td>6088376349846612406</td>\n",
       "      <td>d51a157d2b1e0e9aed4dd7f9900b85b2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.9.9</td>\n",
       "      <td>vivo</td>\n",
       "      <td>w</td>\n",
       "      <td>8.1.0</td>\n",
       "      <td>4.940656e-324</td>\n",
       "      <td>4.940656e-324</td>\n",
       "      <td>V1818T</td>\n",
       "      <td>1573377044359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>67dd9dac18cce1a6d79e8f20eefd98ab</td>\n",
       "      <td>5343094189765291622</td>\n",
       "      <td>625dc45744f59ddbc3ec8df161217188</td>\n",
       "      <td>0</td>\n",
       "      <td>2.1.1</td>\n",
       "      <td>xiaomi</td>\n",
       "      <td>w</td>\n",
       "      <td>9</td>\n",
       "      <td>1.167509e+02</td>\n",
       "      <td>3.656831e+01</td>\n",
       "      <td>Redmi Note 7</td>\n",
       "      <td>1573380989662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11376676</td>\n",
       "      <td>11376677</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>04d9da051fd19038824ff5e62231999b</td>\n",
       "      <td>2243097017724653319</td>\n",
       "      <td>22f0487299a136c32ca50881a9e7e837</td>\n",
       "      <td>0</td>\n",
       "      <td>2.1.5</td>\n",
       "      <td>HONOR</td>\n",
       "      <td>o</td>\n",
       "      <td>9</td>\n",
       "      <td>1.057023e+02</td>\n",
       "      <td>2.962280e+01</td>\n",
       "      <td>HRY-AL00a</td>\n",
       "      <td>1573208907130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11376677</td>\n",
       "      <td>11376678</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>04d9da051fd19038824ff5e62231999b</td>\n",
       "      <td>2263062300471437930</td>\n",
       "      <td>22f0487299a136c32ca50881a9e7e837</td>\n",
       "      <td>4</td>\n",
       "      <td>2.1.5</td>\n",
       "      <td>HONOR</td>\n",
       "      <td>o</td>\n",
       "      <td>9</td>\n",
       "      <td>1.057023e+02</td>\n",
       "      <td>2.962280e+01</td>\n",
       "      <td>HRY-AL00a</td>\n",
       "      <td>1573209232467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11376678</td>\n",
       "      <td>11376679</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>04d9da051fd19038824ff5e62231999b</td>\n",
       "      <td>3805019430149772895</td>\n",
       "      <td>22f0487299a136c32ca50881a9e7e837</td>\n",
       "      <td>0</td>\n",
       "      <td>2.1.5</td>\n",
       "      <td>HONOR</td>\n",
       "      <td>w</td>\n",
       "      <td>9</td>\n",
       "      <td>1.057023e+02</td>\n",
       "      <td>2.962280e+01</td>\n",
       "      <td>HRY-AL00a</td>\n",
       "      <td>1573253363853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11376679</td>\n",
       "      <td>11376680</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>04d9da051fd19038824ff5e62231999b</td>\n",
       "      <td>3834534693777959342</td>\n",
       "      <td>22f0487299a136c32ca50881a9e7e837</td>\n",
       "      <td>1</td>\n",
       "      <td>2.1.5</td>\n",
       "      <td>HONOR</td>\n",
       "      <td>o</td>\n",
       "      <td>9</td>\n",
       "      <td>1.057023e+02</td>\n",
       "      <td>2.962280e+01</td>\n",
       "      <td>HRY-AL00a</td>\n",
       "      <td>1573208896400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11376680</td>\n",
       "      <td>11376681</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>04d9da051fd19038824ff5e62231999b</td>\n",
       "      <td>7188998647991815858</td>\n",
       "      <td>22f0487299a136c32ca50881a9e7e837</td>\n",
       "      <td>0</td>\n",
       "      <td>2.1.5</td>\n",
       "      <td>HONOR</td>\n",
       "      <td>o</td>\n",
       "      <td>9</td>\n",
       "      <td>1.057022e+02</td>\n",
       "      <td>2.962216e+01</td>\n",
       "      <td>HRY-AL00a</td>\n",
       "      <td>1573253374968</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11376681 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                id  target  timestamp                          deviceid  \\\n",
       "0                1       0        NaN  8b2d7f2aed47ab32e9c6ae4f5ae00147   \n",
       "1                2       0        NaN  8b2d7f2aed47ab32e9c6ae4f5ae00147   \n",
       "2                3       0        NaN  832aaa33cdf4a0938ba2c795eb3ffefd   \n",
       "3                4       0        NaN  832aaa33cdf4a0938ba2c795eb3ffefd   \n",
       "4                5       0        NaN  67dd9dac18cce1a6d79e8f20eefd98ab   \n",
       "...            ...     ...        ...                               ...   \n",
       "11376676  11376677       0        NaN  04d9da051fd19038824ff5e62231999b   \n",
       "11376677  11376678       0        NaN  04d9da051fd19038824ff5e62231999b   \n",
       "11376678  11376679       0        NaN  04d9da051fd19038824ff5e62231999b   \n",
       "11376679  11376680       0        NaN  04d9da051fd19038824ff5e62231999b   \n",
       "11376680  11376681       0        NaN  04d9da051fd19038824ff5e62231999b   \n",
       "\n",
       "                       newsid                              guid  pos  \\\n",
       "0         8008333091915950969  9a2c909ebc47aec49d9c160cdb4a6572    1   \n",
       "1         8008333091915950969  9a2c909ebc47aec49d9c160cdb4a6572    1   \n",
       "2         4941885624885390992  d51a157d2b1e0e9aed4dd7f9900b85b2    2   \n",
       "3         6088376349846612406  d51a157d2b1e0e9aed4dd7f9900b85b2    1   \n",
       "4         5343094189765291622  625dc45744f59ddbc3ec8df161217188    0   \n",
       "...                       ...                               ...  ...   \n",
       "11376676  2243097017724653319  22f0487299a136c32ca50881a9e7e837    0   \n",
       "11376677  2263062300471437930  22f0487299a136c32ca50881a9e7e837    4   \n",
       "11376678  3805019430149772895  22f0487299a136c32ca50881a9e7e837    0   \n",
       "11376679  3834534693777959342  22f0487299a136c32ca50881a9e7e837    1   \n",
       "11376680  7188998647991815858  22f0487299a136c32ca50881a9e7e837    0   \n",
       "\n",
       "         app_version device_vendor netmodel osversion            lng  \\\n",
       "0              2.1.5         HONOR       g4         9   1.125385e+02   \n",
       "1              2.1.5         HONOR        w         9   1.117312e+02   \n",
       "2              1.9.9          vivo        w     8.1.0  4.940656e-324   \n",
       "3              1.9.9          vivo        w     8.1.0  4.940656e-324   \n",
       "4              2.1.1        xiaomi        w         9   1.167509e+02   \n",
       "...              ...           ...      ...       ...            ...   \n",
       "11376676       2.1.5         HONOR        o         9   1.057023e+02   \n",
       "11376677       2.1.5         HONOR        o         9   1.057023e+02   \n",
       "11376678       2.1.5         HONOR        w         9   1.057023e+02   \n",
       "11376679       2.1.5         HONOR        o         9   1.057023e+02   \n",
       "11376680       2.1.5         HONOR        o         9   1.057022e+02   \n",
       "\n",
       "                    lat device_version             ts  \n",
       "0          3.783793e+01       STF-AL00  1573298086436  \n",
       "1          3.562274e+01       STF-AL00  1573298087570  \n",
       "2         4.940656e-324         V1818T  1573377075934  \n",
       "3         4.940656e-324         V1818T  1573377044359  \n",
       "4          3.656831e+01   Redmi Note 7  1573380989662  \n",
       "...                 ...            ...            ...  \n",
       "11376676   2.962280e+01      HRY-AL00a  1573208907130  \n",
       "11376677   2.962280e+01      HRY-AL00a  1573209232467  \n",
       "11376678   2.962280e+01      HRY-AL00a  1573253363853  \n",
       "11376679   2.962280e+01      HRY-AL00a  1573208896400  \n",
       "11376680   2.962216e+01      HRY-AL00a  1573253374968  \n",
       "\n",
       "[11376681 rows x 15 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df[train_df.deviceid.str[-1] == '1']\n",
    "test_df = test_df[test_df.deviceid.str[-1] == '1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>deviceid</th>\n",
       "      <th>newsid</th>\n",
       "      <th>guid</th>\n",
       "      <th>pos</th>\n",
       "      <th>app_version</th>\n",
       "      <th>device_vendor</th>\n",
       "      <th>netmodel</th>\n",
       "      <th>osversion</th>\n",
       "      <th>lng</th>\n",
       "      <th>lat</th>\n",
       "      <th>device_version</th>\n",
       "      <th>ts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fc2537a764aeebad1d9738bd835830c1</td>\n",
       "      <td>1027465147051722167</td>\n",
       "      <td>7a7e251a3a8a3e51f304558189d920f8</td>\n",
       "      <td>0</td>\n",
       "      <td>2.1.5</td>\n",
       "      <td>OPPO</td>\n",
       "      <td>o</td>\n",
       "      <td>8.1.0</td>\n",
       "      <td>4.940656e-324</td>\n",
       "      <td>4.940656e-324</td>\n",
       "      <td>PBCM10</td>\n",
       "      <td>1573365555907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fc2537a764aeebad1d9738bd835830c1</td>\n",
       "      <td>1087291812511982332</td>\n",
       "      <td>7a7e251a3a8a3e51f304558189d920f8</td>\n",
       "      <td>1</td>\n",
       "      <td>2.1.5</td>\n",
       "      <td>OPPO</td>\n",
       "      <td>w</td>\n",
       "      <td>8.1.0</td>\n",
       "      <td>4.940656e-324</td>\n",
       "      <td>4.940656e-324</td>\n",
       "      <td>PBCM10</td>\n",
       "      <td>1573219855445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fc2537a764aeebad1d9738bd835830c1</td>\n",
       "      <td>1227506534075035258</td>\n",
       "      <td>7a7e251a3a8a3e51f304558189d920f8</td>\n",
       "      <td>6</td>\n",
       "      <td>2.1.5</td>\n",
       "      <td>OPPO</td>\n",
       "      <td>o</td>\n",
       "      <td>8.1.0</td>\n",
       "      <td>4.940656e-324</td>\n",
       "      <td>4.940656e-324</td>\n",
       "      <td>PBCM10</td>\n",
       "      <td>1573364924458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fc2537a764aeebad1d9738bd835830c1</td>\n",
       "      <td>1423728582189605531</td>\n",
       "      <td>7a7e251a3a8a3e51f304558189d920f8</td>\n",
       "      <td>2</td>\n",
       "      <td>2.1.5</td>\n",
       "      <td>OPPO</td>\n",
       "      <td>o</td>\n",
       "      <td>8.1.0</td>\n",
       "      <td>4.940656e-324</td>\n",
       "      <td>4.940656e-324</td>\n",
       "      <td>PBCM10</td>\n",
       "      <td>1573368698189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74</td>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "      <td>1.573221e+12</td>\n",
       "      <td>fc2537a764aeebad1d9738bd835830c1</td>\n",
       "      <td>1441205267295707622</td>\n",
       "      <td>7a7e251a3a8a3e51f304558189d920f8</td>\n",
       "      <td>0</td>\n",
       "      <td>2.1.5</td>\n",
       "      <td>OPPO</td>\n",
       "      <td>o</td>\n",
       "      <td>8.1.0</td>\n",
       "      <td>1.060517e+02</td>\n",
       "      <td>2.796989e+01</td>\n",
       "      <td>PBCM10</td>\n",
       "      <td>1573221210580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11376592</td>\n",
       "      <td>11376593</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cfc14bedafdb8e16cef58e9fbd341521</td>\n",
       "      <td>5089438139728483409</td>\n",
       "      <td>f6089c7ede136d61d841991c810ca7d0</td>\n",
       "      <td>6</td>\n",
       "      <td>2.1.5</td>\n",
       "      <td>OPPO</td>\n",
       "      <td>o</td>\n",
       "      <td>7.1.1</td>\n",
       "      <td>1.061475e+02</td>\n",
       "      <td>2.631059e+01</td>\n",
       "      <td>OPPO R11 Plusk</td>\n",
       "      <td>1573210421908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11376593</td>\n",
       "      <td>11376594</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cfc14bedafdb8e16cef58e9fbd341521</td>\n",
       "      <td>6402821250564788264</td>\n",
       "      <td>f6089c7ede136d61d841991c810ca7d0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.1.5</td>\n",
       "      <td>OPPO</td>\n",
       "      <td>w</td>\n",
       "      <td>7.1.1</td>\n",
       "      <td>1.061475e+02</td>\n",
       "      <td>2.631049e+01</td>\n",
       "      <td>OPPO R11 Plusk</td>\n",
       "      <td>1573213174447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11376594</td>\n",
       "      <td>11376595</td>\n",
       "      <td>1</td>\n",
       "      <td>1.573209e+12</td>\n",
       "      <td>cfc14bedafdb8e16cef58e9fbd341521</td>\n",
       "      <td>6680219466561420334</td>\n",
       "      <td>9b8fa426ef383f1c54aa27fc64aca3bb</td>\n",
       "      <td>1</td>\n",
       "      <td>2.1.5</td>\n",
       "      <td>OPPO</td>\n",
       "      <td>o</td>\n",
       "      <td>7.1.1</td>\n",
       "      <td>1.061475e+02</td>\n",
       "      <td>2.631059e+01</td>\n",
       "      <td>OPPO R11 Plusk</td>\n",
       "      <td>1573208822829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11376595</td>\n",
       "      <td>11376596</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cfc14bedafdb8e16cef58e9fbd341521</td>\n",
       "      <td>7562913808494695558</td>\n",
       "      <td>9b8fa426ef383f1c54aa27fc64aca3bb</td>\n",
       "      <td>5</td>\n",
       "      <td>2.1.5</td>\n",
       "      <td>OPPO</td>\n",
       "      <td>o</td>\n",
       "      <td>7.1.1</td>\n",
       "      <td>1.061475e+02</td>\n",
       "      <td>2.631059e+01</td>\n",
       "      <td>OPPO R11 Plusk</td>\n",
       "      <td>1573209144137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11376596</td>\n",
       "      <td>11376597</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cfc14bedafdb8e16cef58e9fbd341521</td>\n",
       "      <td>8731568421816937146</td>\n",
       "      <td>9b8fa426ef383f1c54aa27fc64aca3bb</td>\n",
       "      <td>1</td>\n",
       "      <td>2.1.5</td>\n",
       "      <td>OPPO</td>\n",
       "      <td>w</td>\n",
       "      <td>7.1.1</td>\n",
       "      <td>1.061475e+02</td>\n",
       "      <td>2.631059e+01</td>\n",
       "      <td>OPPO R11 Plusk</td>\n",
       "      <td>1573209194651</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>734116 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                id  target     timestamp                          deviceid  \\\n",
       "70              71       0           NaN  fc2537a764aeebad1d9738bd835830c1   \n",
       "71              72       0           NaN  fc2537a764aeebad1d9738bd835830c1   \n",
       "72              73       0           NaN  fc2537a764aeebad1d9738bd835830c1   \n",
       "73              74       0           NaN  fc2537a764aeebad1d9738bd835830c1   \n",
       "74              75       1  1.573221e+12  fc2537a764aeebad1d9738bd835830c1   \n",
       "...            ...     ...           ...                               ...   \n",
       "11376592  11376593       0           NaN  cfc14bedafdb8e16cef58e9fbd341521   \n",
       "11376593  11376594       0           NaN  cfc14bedafdb8e16cef58e9fbd341521   \n",
       "11376594  11376595       1  1.573209e+12  cfc14bedafdb8e16cef58e9fbd341521   \n",
       "11376595  11376596       0           NaN  cfc14bedafdb8e16cef58e9fbd341521   \n",
       "11376596  11376597       0           NaN  cfc14bedafdb8e16cef58e9fbd341521   \n",
       "\n",
       "                       newsid                              guid  pos  \\\n",
       "70        1027465147051722167  7a7e251a3a8a3e51f304558189d920f8    0   \n",
       "71        1087291812511982332  7a7e251a3a8a3e51f304558189d920f8    1   \n",
       "72        1227506534075035258  7a7e251a3a8a3e51f304558189d920f8    6   \n",
       "73        1423728582189605531  7a7e251a3a8a3e51f304558189d920f8    2   \n",
       "74        1441205267295707622  7a7e251a3a8a3e51f304558189d920f8    0   \n",
       "...                       ...                               ...  ...   \n",
       "11376592  5089438139728483409  f6089c7ede136d61d841991c810ca7d0    6   \n",
       "11376593  6402821250564788264  f6089c7ede136d61d841991c810ca7d0    0   \n",
       "11376594  6680219466561420334  9b8fa426ef383f1c54aa27fc64aca3bb    1   \n",
       "11376595  7562913808494695558  9b8fa426ef383f1c54aa27fc64aca3bb    5   \n",
       "11376596  8731568421816937146  9b8fa426ef383f1c54aa27fc64aca3bb    1   \n",
       "\n",
       "         app_version device_vendor netmodel osversion            lng  \\\n",
       "70             2.1.5          OPPO        o     8.1.0  4.940656e-324   \n",
       "71             2.1.5          OPPO        w     8.1.0  4.940656e-324   \n",
       "72             2.1.5          OPPO        o     8.1.0  4.940656e-324   \n",
       "73             2.1.5          OPPO        o     8.1.0  4.940656e-324   \n",
       "74             2.1.5          OPPO        o     8.1.0   1.060517e+02   \n",
       "...              ...           ...      ...       ...            ...   \n",
       "11376592       2.1.5          OPPO        o     7.1.1   1.061475e+02   \n",
       "11376593       2.1.5          OPPO        w     7.1.1   1.061475e+02   \n",
       "11376594       2.1.5          OPPO        o     7.1.1   1.061475e+02   \n",
       "11376595       2.1.5          OPPO        o     7.1.1   1.061475e+02   \n",
       "11376596       2.1.5          OPPO        w     7.1.1   1.061475e+02   \n",
       "\n",
       "                    lat  device_version             ts  \n",
       "70        4.940656e-324          PBCM10  1573365555907  \n",
       "71        4.940656e-324          PBCM10  1573219855445  \n",
       "72        4.940656e-324          PBCM10  1573364924458  \n",
       "73        4.940656e-324          PBCM10  1573368698189  \n",
       "74         2.796989e+01          PBCM10  1573221210580  \n",
       "...                 ...             ...            ...  \n",
       "11376592   2.631059e+01  OPPO R11 Plusk  1573210421908  \n",
       "11376593   2.631049e+01  OPPO R11 Plusk  1573213174447  \n",
       "11376594   2.631059e+01  OPPO R11 Plusk  1573208822829  \n",
       "11376595   2.631059e+01  OPPO R11 Plusk  1573209144137  \n",
       "11376596   2.631059e+01  OPPO R11 Plusk  1573209194651  \n",
       "\n",
       "[734116 rows x 15 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================================== read train ===============================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/iflow/wanghuibo/apps/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n",
      "/home/iflow/wanghuibo/apps/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n",
      "/home/iflow/wanghuibo/apps/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py:494: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runtime: 2.2466742992401123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/iflow/wanghuibo/apps/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  del sys.path[0]\n",
      "/home/iflow/wanghuibo/apps/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "print('=============================================== read train ===============================================')\n",
    "t = time.time()\n",
    "# train_df = pd.read_csv('dataset/train.csv')\n",
    "train_df['date'] = pd.to_datetime(\n",
    "    train_df['ts'].apply(lambda x: time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(x / 1000)))\n",
    ")\n",
    "train_df['day'] = train_df['date'].dt.day\n",
    "\n",
    "# 训练集中，day=7的个数为11个，day=8的为3,674,871。 day9，10也是解决40w\n",
    "# day=7占比不到1/百万，属于异常情况，去掉合理？ 线上的表现又会如何，为啥不是直接删除，这样有点过了\n",
    "# 这里为啥只是改了day，不去直接改ts和timestamp呢？\n",
    "train_df.loc[train_df['day'] == 7, 'day'] = 8\n",
    "train_df['hour'] = train_df['date'].dt.hour\n",
    "train_df['minute'] = train_df['date'].dt.minute\n",
    "train_num = train_df.shape[0]\n",
    "labels = train_df['target'].values\n",
    "print('runtime:', time.time() - t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================================== click data ===============================================\n",
      "runtime: 2.605297088623047\n"
     ]
    }
   ],
   "source": [
    "print('=============================================== click data ===============================================')\n",
    "click_df = train_df[train_df['target'] == 1].sort_values('timestamp').reset_index(drop=True)\n",
    "click_df['exposure_click_gap'] = click_df['timestamp'] - click_df['ts']\n",
    "click_df = click_df[click_df['exposure_click_gap'] >= 0].reset_index(drop=True)\n",
    "click_df['date'] = pd.to_datetime(\n",
    "    click_df['timestamp'].apply(lambda x: time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(x / 1000)))\n",
    ")\n",
    "click_df['day'] = click_df['date'].dt.day\n",
    "# 同上对day==7的修改\n",
    "click_df.loc[click_df['day'] == 7, 'day'] = 8\n",
    "\n",
    "del train_df['target'], train_df['timestamp']\n",
    "\n",
    "# 这里为啥要把click_df的这些字段删除呢？\n",
    "for f in ['date', 'exposure_click_gap', 'timestamp', 'ts', 'target', 'hour', 'minute']:\n",
    "    del click_df[f]\n",
    "print('runtime:', time.time() - t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================================== read test ===============================================\n",
      "runtime: 3.7961087226867676\n"
     ]
    }
   ],
   "source": [
    "print('=============================================== read test ===============================================')\n",
    "test_df['date'] = pd.to_datetime(\n",
    "    test_df['ts'].apply(lambda x: time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(x / 1000)))\n",
    ")\n",
    "test_df['day'] = test_df['date'].dt.day\n",
    "\n",
    "# 测试集中，day=10的个数为32个，day=11的为3,653,560占比 1/十万，属于异常情况，去掉合理\n",
    "test_df.loc[test_df['day'] == 10, 'day'] = 11\n",
    "test_df['hour'] = test_df['date'].dt.hour\n",
    "test_df['minute'] = test_df['date'].dt.minute\n",
    "df = pd.concat([train_df, test_df], axis=0, ignore_index=False)\n",
    "del train_df, test_df, df['date']\n",
    "gc.collect()\n",
    "print('runtime:', time.time() - t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================= category encoding =============================================\n",
      "deviceid\n",
      "newsid\n",
      "pos\n",
      "app_version\n",
      "device_vendor\n",
      "netmodel\n",
      "osversion\n",
      "device_version\n",
      "lng\n",
      "lat\n",
      "lng_lat\n",
      "166.76 Mb, 81.53 Mb (51.11 %)\n",
      "4.87 Mb, 2.29 Mb (52.94 %)\n",
      "77.82 Mb, 35.20 Mb (54.76 %)\n",
      "runtime: 17.060081243515015\n"
     ]
    }
   ],
   "source": [
    "print('============================================= category encoding =============================================')\n",
    "df['lng_lat'] = df['lng'].astype('str') + '_' + df['lat'].astype('str')\n",
    "del df['guid']\n",
    "click_df['lng_lat'] = click_df['lng'].astype('str') + '_' + click_df['lat'].astype('str')\n",
    "sort_df = df.sort_values('ts').reset_index(drop=True)\n",
    "cate_cols = [\n",
    "    'deviceid', 'newsid', 'pos', 'app_version', 'device_vendor',\n",
    "    'netmodel', 'osversion', 'device_version', 'lng', 'lat', 'lng_lat'\n",
    "]\n",
    "for f in cate_cols:\n",
    "    print(f)\n",
    "    map_dict = dict(zip(df[f].unique(), range(df[f].nunique())))\n",
    "    df[f] = df[f].map(map_dict).fillna(-1).astype('int32')\n",
    "    click_df[f] = click_df[f].map(map_dict).fillna(-1).astype('int32')\n",
    "    sort_df[f] = sort_df[f].map(map_dict).fillna(-1).astype('int32')\n",
    "    df[f + '_count'] = df[f].map(df[f].value_counts())\n",
    "df = reduce_mem(df)\n",
    "click_df = reduce_mem(click_df)\n",
    "sort_df = reduce_mem(sort_df)\n",
    "print('runtime:', time.time() - t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================= feat engineer =============================================\n",
      "*************************** history stats ***************************\n",
      "------------------ deviceid ------------------\n",
      "runtime: 17.984237909317017\n",
      "------------------ pos_deviceid ------------------\n",
      "runtime: 18.938199043273926\n",
      "126.00 Mb, 92.64 Mb (26.47 %)\n"
     ]
    }
   ],
   "source": [
    "print('============================================= feat engineer =============================================')\n",
    "\n",
    "print('*************************** history stats ***************************')\n",
    "for f in [\n",
    "    ['deviceid'],\n",
    "    ['pos', 'deviceid'],\n",
    "    # ...\n",
    "]:\n",
    "    print('------------------ {} ------------------'.format('_'.join(f)))\n",
    "\n",
    "    # 对前一天的点击次数进行统计\n",
    "    tmp = click_df[f + ['day', 'id']].groupby(f + ['day'], as_index=False)['id'].agg(\n",
    "        {'_'.join(f) + '_prev_day_click_count': 'count'})\n",
    "    tmp['day'] += 1\n",
    "    df = df.merge(tmp, on=f + ['day'], how='left')\n",
    "    df['_'.join(f) + '_prev_day_click_count'] = df['_'.join(f) + '_prev_day_click_count'].fillna(0)\n",
    "    df.loc[df['day'] == 8, '_'.join(f) + '_prev_day_click_count'] = None\n",
    "\n",
    "    # 对前一天的曝光量进行统计\n",
    "    tmp = df[f + ['day', 'id']].groupby(f + ['day'], as_index=False)['id'].agg(\n",
    "        {'_'.join(f) + '_prev_day_count': 'count'})\n",
    "    tmp['day'] += 1\n",
    "    df = df.merge(tmp, on=f + ['day'], how='left')\n",
    "    df['_'.join(f) + '_prev_day_count'] = df['_'.join(f) + '_prev_day_count'].fillna(0)\n",
    "    df.loc[df['day'] == 8, '_'.join(f) + '_prev_day_count'] = None\n",
    "\n",
    "    # 计算前一天的点击率\n",
    "    df['_'.join(f) + '_prev_day_ctr'] = df['_'.join(f) + '_prev_day_click_count'] / (\n",
    "            df['_'.join(f) + '_prev_day_count'] + df['_'.join(f) + '_prev_day_count'].mean())\n",
    "\n",
    "    del tmp\n",
    "    print('runtime:', time.time() - t)\n",
    "del click_df\n",
    "df = reduce_mem(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************************** exposure_ts_gap ***************************\n",
      "------------------ deviceid ------------------\n",
      "166.76 Mb, 129.70 Mb (22.22 %)\n",
      "runtime: 25.288307428359985\n",
      "------------------ newsid ------------------\n",
      "203.82 Mb, 166.76 Mb (18.18 %)\n",
      "runtime: 32.0676703453064\n",
      "------------------ lng_lat ------------------\n",
      "240.87 Mb, 203.82 Mb (15.38 %)\n",
      "runtime: 38.498669385910034\n",
      "------------------ pos_deviceid ------------------\n",
      "277.93 Mb, 240.87 Mb (13.33 %)\n",
      "runtime: 45.52155923843384\n",
      "------------------ pos_newsid ------------------\n",
      "314.99 Mb, 277.93 Mb (11.76 %)\n",
      "runtime: 53.76559090614319\n",
      "------------------ pos_lng_lat ------------------\n",
      "352.05 Mb, 314.99 Mb (10.53 %)\n",
      "runtime: 61.59986066818237\n",
      "------------------ pos_deviceid_lng_lat ------------------\n",
      "389.10 Mb, 352.05 Mb (9.52 %)\n",
      "runtime: 70.06639742851257\n",
      "------------------ netmodel_deviceid ------------------\n",
      "426.16 Mb, 389.10 Mb (8.70 %)\n",
      "runtime: 78.45123648643494\n",
      "------------------ pos_netmodel_deviceid ------------------\n",
      "463.22 Mb, 426.16 Mb (8.00 %)\n",
      "runtime: 87.38917016983032\n",
      "------------------ netmodel_lng_lat ------------------\n",
      "500.28 Mb, 463.22 Mb (7.41 %)\n",
      "runtime: 96.42328381538391\n",
      "------------------ deviceid_lng_lat ------------------\n",
      "537.33 Mb, 500.28 Mb (6.90 %)\n",
      "runtime: 105.74487042427063\n",
      "------------------ netmodel_deviceid_lng_lat ------------------\n",
      "574.39 Mb, 537.33 Mb (6.45 %)\n",
      "runtime: 115.70647025108337\n",
      "------------------ pos_netmodel_lng_lat ------------------\n",
      "611.45 Mb, 574.39 Mb (6.06 %)\n",
      "runtime: 126.04649639129639\n",
      "------------------ pos_netmodel_deviceid_lng_lat ------------------\n",
      "648.51 Mb, 611.45 Mb (5.71 %)\n",
      "runtime: 136.94181895256042\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('*************************** exposure_ts_gap ***************************')\n",
    "for f in [\n",
    "    ['deviceid'], ['newsid'], ['lng_lat'],\n",
    "    ['pos', 'deviceid'], ['pos', 'newsid'], ['pos', 'lng_lat'],\n",
    "    ['pos', 'deviceid', 'lng_lat'],\n",
    "    ['netmodel', 'deviceid'],\n",
    "    ['pos', 'netmodel', 'deviceid'],\n",
    "    ['netmodel', 'lng_lat'], ['deviceid', 'lng_lat'],\n",
    "    ['netmodel', 'deviceid', 'lng_lat'], ['pos', 'netmodel', 'lng_lat'],\n",
    "    ['pos', 'netmodel', 'deviceid', 'lng_lat']\n",
    "]:\n",
    "    print('------------------ {} ------------------'.format('_'.join(f)))\n",
    "\n",
    "    tmp = sort_df[f + ['ts']].groupby(f)\n",
    "    # 前x次、后x次曝光到当前的时间差\n",
    "    for gap in [1, 2, 3, 5, 10]:\n",
    "        sort_df['{}_prev{}_exposure_ts_gap'.format('_'.join(f), gap)] = tmp['ts'].shift(0) - tmp['ts'].shift(gap)\n",
    "        sort_df['{}_next{}_exposure_ts_gap'.format('_'.join(f), gap)] = tmp['ts'].shift(-gap) - tmp['ts'].shift(0)\n",
    "        tmp2 = sort_df[\n",
    "            f + ['ts', '{}_prev{}_exposure_ts_gap'.format('_'.join(f), gap),\n",
    "                 '{}_next{}_exposure_ts_gap'.format('_'.join(f), gap)]\n",
    "            ].drop_duplicates(f + ['ts']).reset_index(drop=True)\n",
    "        df = df.merge(tmp2, on=f + ['ts'], how='left')\n",
    "        del sort_df['{}_prev{}_exposure_ts_gap'.format('_'.join(f), gap)]\n",
    "        del sort_df['{}_next{}_exposure_ts_gap'.format('_'.join(f), gap)]\n",
    "        del tmp2\n",
    "\n",
    "    del tmp\n",
    "    df = reduce_mem(df)\n",
    "    print('runtime:', time.time() - t)\n",
    "del df['ts']\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyspark.sql import Row\n",
    "# from pyspark import SparkConf\n",
    "# from pyspark import SparkContext\n",
    "\n",
    "# conf = SparkConf()\n",
    "# conf.setAppName(\"[陈亮时/149675]-[tf_format_test]\")\n",
    "# sc = SparkContext(conf=conf)\n",
    "    \n",
    "# l = [('Ankit',25),('Jalfaizy',22),('saurabh',20),('Bala',26)]\n",
    "# rdd = sc.parallelize(l)\n",
    "# people = rdd.map(lambda x: Row(name=x[0], age=int(x[1])))\n",
    "# schemaPeople = sqlContext.createDataFrame(people)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('*************************** cross feat (second order) ***************************')\n",
    "# # 二阶交叉特征，可以继续做更高阶的交叉。\n",
    "# def build_cross_feat(df, f, col):\n",
    "#     print('------------------ {} {} ------------------'.format(f, col))\n",
    "#     df = df.merge(df[[f, col]].groupby(f, as_index=False)[col].agg({\n",
    "#         'cross_{}_{}_nunique'.format(f, col): 'nunique',\n",
    "#         'cross_{}_{}_ent'.format(f, col): lambda x: entropy(x.value_counts() / x.shape[0])  # 熵\n",
    "#     }), on=f, how='left')\n",
    "#     if 'cross_{}_{}_count'.format(f, col) not in df.columns.values and 'cross_{}_{}_count'.format(col,\n",
    "#                                                                                                   f) not in df.columns.values:\n",
    "#         df = df.merge(df[[f, col, 'id']].groupby([f, col], as_index=False)['id'].agg({\n",
    "#             'cross_{}_{}_count'.format(f, col): 'count'  # 共现次数\n",
    "#         }), on=[f, col], how='left')\n",
    "#     if 'cross_{}_{}_count_ratio'.format(col, f) not in df.columns.values:\n",
    "#         df['cross_{}_{}_count_ratio'.format(col, f)] = df['cross_{}_{}_count'.format(f, col)] / df[\n",
    "#             f + '_count']  # 比例偏好\n",
    "#     if 'cross_{}_{}_count_ratio'.format(f, col) not in df.columns.values:\n",
    "#         df['cross_{}_{}_count_ratio'.format(f, col)] = df['cross_{}_{}_count'.format(f, col)] / df[\n",
    "#             col + '_count']  # 比例偏好\n",
    "#     df['cross_{}_{}_nunique_ratio_{}_count'.format(f, col, f)] = df['cross_{}_{}_nunique'.format(f, col)] / df[\n",
    "#         f + '_count']\n",
    "#     print('runtime:', time.time() - t)\n",
    "#     df = reduce_mem(df)\n",
    "#     return df\n",
    "        \n",
    "# cross_cols = ['deviceid', 'newsid', 'pos', 'netmodel', 'lng_lat']\n",
    "# f_col_tuple_list = []\n",
    "# for f in cross_cols:\n",
    "#     for col in cross_cols:\n",
    "#         if col == f:\n",
    "#             continue\n",
    "#         f_col_tuple_list.append((f, col))\n",
    "        \n",
    "# print(f_col_tuple_list)\n",
    "# # with concurrent.futures.ProcessPoolExecutor(num_processes) as pool:\n",
    "# #     df = list(tqdm.tqdm(pool.map(build_cross_feat, cross_cols, chunksize=10, total=df.shape[0])))\n",
    "# for tuple_o in tqdm.tqdm(f_col_tuple_list):\n",
    "#     print(tuple_o)\n",
    "#     df = build_cross_feat(df, tuple_o[0], tuple_o[1])\n",
    "\n",
    "# del df['id']\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************************** cross feat (second order) ***************************\n",
      "------------------ deviceid newsid ------------------\n",
      "runtime: 149.09444093704224\n",
      "------------------ deviceid pos ------------------\n",
      "runtime: 159.9373984336853\n",
      "------------------ deviceid netmodel ------------------\n",
      "runtime: 171.00094175338745\n",
      "------------------ deviceid lng_lat ------------------\n",
      "runtime: 182.43015956878662\n",
      "781.91 Mb, 645.73 Mb (17.42 %)\n",
      "------------------ newsid deviceid ------------------\n",
      "runtime: 575.3607921600342\n",
      "------------------ newsid pos ------------------\n",
      "runtime: 983.6665697097778\n",
      "------------------ newsid netmodel ------------------\n",
      "runtime: 1379.0395348072052\n",
      "------------------ newsid lng_lat ------------------\n",
      "runtime: 1771.5170404911041\n",
      "801.37 Mb, 682.78 Mb (14.80 %)\n",
      "------------------ pos deviceid ------------------\n",
      "runtime: 1775.6361346244812\n",
      "------------------ pos newsid ------------------\n",
      "runtime: 1778.2754430770874\n",
      "------------------ pos netmodel ------------------\n",
      "runtime: 1783.168639421463\n",
      "------------------ pos lng_lat ------------------\n",
      "runtime: 1788.4117560386658\n",
      "816.19 Mb, 720.77 Mb (11.69 %)\n",
      "------------------ netmodel deviceid ------------------\n",
      "runtime: 1794.0664312839508\n",
      "------------------ netmodel newsid ------------------\n",
      "runtime: 1797.8940091133118\n",
      "------------------ netmodel pos ------------------\n",
      "runtime: 1801.59801363945\n",
      "------------------ netmodel lng_lat ------------------\n",
      "runtime: 1808.9744846820831\n",
      "831.94 Mb, 751.34 Mb (9.69 %)\n",
      "------------------ lng_lat deviceid ------------------\n",
      "runtime: 1852.7943511009216\n",
      "------------------ lng_lat newsid ------------------\n",
      "runtime: 1894.8238821029663\n",
      "------------------ lng_lat pos ------------------\n",
      "runtime: 1936.789220571518\n",
      "------------------ lng_lat netmodel ------------------\n",
      "runtime: 1979.1730046272278\n",
      "840.28 Mb, 773.57 Mb (7.94 %)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('*************************** cross feat (second order) ***************************')\n",
    "# 二阶交叉特征，可以继续做更高阶的交叉。\n",
    "cross_cols = ['deviceid', 'newsid', 'pos', 'netmodel', 'lng_lat']\n",
    "for f in cross_cols:\n",
    "    for col in cross_cols:\n",
    "        if col == f:\n",
    "            continue\n",
    "        print('------------------ {} {} ------------------'.format(f, col))\n",
    "        df = df.merge(df[[f, col]].groupby(f, as_index=False)[col].agg({\n",
    "            'cross_{}_{}_nunique'.format(f, col): 'nunique',\n",
    "            'cross_{}_{}_ent'.format(f, col): lambda x: entropy(x.value_counts() / x.shape[0])  # 熵\n",
    "        }), on=f, how='left')\n",
    "        if 'cross_{}_{}_count'.format(f, col) not in df.columns.values and 'cross_{}_{}_count'.format(col,\n",
    "                                                                                                      f) not in df.columns.values:\n",
    "            df = df.merge(df[[f, col, 'id']].groupby([f, col], as_index=False)['id'].agg({\n",
    "                'cross_{}_{}_count'.format(f, col): 'count'  # 共现次数\n",
    "            }), on=[f, col], how='left')\n",
    "        if 'cross_{}_{}_count_ratio'.format(col, f) not in df.columns.values:\n",
    "            df['cross_{}_{}_count_ratio'.format(col, f)] = df['cross_{}_{}_count'.format(f, col)] / df[\n",
    "                f + '_count']  # 比例偏好\n",
    "        if 'cross_{}_{}_count_ratio'.format(f, col) not in df.columns.values:\n",
    "            df['cross_{}_{}_count_ratio'.format(f, col)] = df['cross_{}_{}_count'.format(f, col)] / df[\n",
    "                col + '_count']  # 比例偏好\n",
    "        df['cross_{}_{}_nunique_ratio_{}_count'.format(f, col, f)] = df['cross_{}_{}_nunique'.format(f, col)] / df[\n",
    "            f + '_count']\n",
    "        print('runtime:', time.time() - t)\n",
    "    df = reduce_mem(df)\n",
    "del df['id']\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************************** embedding ***************************\n",
      "====================================== deviceid newsid ======================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:MainThread:gensim.models.word2vec:collecting all words and their counts\n",
      "INFO:MainThread:gensim.models.word2vec:PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "INFO:MainThread:gensim.models.word2vec:collected 300717 word types from a corpus of 971439 raw words and 7049 sentences\n",
      "INFO:MainThread:gensim.models.word2vec:Loading a fresh vocabulary\n",
      "INFO:MainThread:gensim.models.word2vec:effective_min_count=5 retains 38716 unique words (12% of original 300717, drops 262001)\n",
      "INFO:MainThread:gensim.models.word2vec:effective_min_count=5 leaves 569569 word corpus (58% of original 971439, drops 401870)\n",
      "INFO:MainThread:gensim.models.word2vec:deleting the raw counts dictionary of 300717 items\n",
      "INFO:MainThread:gensim.models.word2vec:sample=0.001 downsamples 0 most-common words\n",
      "INFO:MainThread:gensim.models.word2vec:downsampling leaves estimated 569569 word corpus (100.0% of prior 569569)\n",
      "INFO:MainThread:gensim.models.word2vec:constructing a huffman tree from 38716 words\n",
      "INFO:MainThread:gensim.models.word2vec:built huffman tree with maximum node depth 17\n",
      "INFO:MainThread:gensim.models.base_any2vec:estimated required memory for 38716 words and 8 dimensions: 30817936 bytes\n",
      "INFO:MainThread:gensim.models.word2vec:resetting layer weights\n",
      "INFO:MainThread:gensim.models.base_any2vec:training model with 3 workers on 38716 vocabulary and 8 features, using sg=0 hs=1 sample=0.001 negative=5 window=5\n",
      "INFO:MainThread:gensim.models.base_any2vec:EPOCH 1 - PROGRESS: at 64.08% examples, 500836 words/s, in_qsize 5, out_qsize 0\n",
      "INFO:MainThread:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:MainThread:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:MainThread:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:MainThread:gensim.models.base_any2vec:EPOCH - 1 : training on 971439 raw words (555389 effective words) took 1.1s, 513041 effective words/s\n",
      "INFO:MainThread:gensim.models.base_any2vec:EPOCH 2 - PROGRESS: at 50.53% examples, 390696 words/s, in_qsize 5, out_qsize 0\n",
      "INFO:MainThread:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:MainThread:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:MainThread:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:MainThread:gensim.models.base_any2vec:EPOCH - 2 : training on 971439 raw words (555389 effective words) took 1.4s, 399671 effective words/s\n",
      "INFO:MainThread:gensim.models.base_any2vec:EPOCH 3 - PROGRESS: at 59.46% examples, 467498 words/s, in_qsize 5, out_qsize 0\n",
      "INFO:MainThread:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:MainThread:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:MainThread:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:MainThread:gensim.models.base_any2vec:EPOCH - 3 : training on 971439 raw words (555389 effective words) took 1.1s, 483801 effective words/s\n",
      "INFO:MainThread:gensim.models.base_any2vec:EPOCH 4 - PROGRESS: at 65.65% examples, 510251 words/s, in_qsize 5, out_qsize 0\n",
      "INFO:MainThread:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:MainThread:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:MainThread:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:MainThread:gensim.models.base_any2vec:EPOCH - 4 : training on 971439 raw words (555389 effective words) took 1.1s, 521422 effective words/s\n",
      "INFO:MainThread:gensim.models.base_any2vec:EPOCH 5 - PROGRESS: at 64.08% examples, 504906 words/s, in_qsize 5, out_qsize 0\n",
      "INFO:MainThread:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:MainThread:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:MainThread:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:MainThread:gensim.models.base_any2vec:EPOCH - 5 : training on 971439 raw words (555389 effective words) took 1.1s, 515360 effective words/s\n",
      "INFO:MainThread:gensim.models.base_any2vec:training on a 4857195 raw words (2776945 effective words) took 5.8s, 480890 effective words/s\n",
      "/home/iflow/wanghuibo/apps/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:22: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
      "/home/iflow/wanghuibo/apps/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:23: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.54 Mb, 0.17 Mb (67.50 %)\n",
      "runtime: 2007.1937282085419\n",
      "====================================== newsid deviceid ======================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:MainThread:gensim.models.word2vec:collecting all words and their counts\n",
      "INFO:MainThread:gensim.models.word2vec:PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "INFO:MainThread:gensim.models.word2vec:PROGRESS: at sentence #10000, processed 210921 words, keeping 6641 word types\n",
      "INFO:MainThread:gensim.models.word2vec:PROGRESS: at sentence #20000, processed 299653 words, keeping 6846 word types\n",
      "INFO:MainThread:gensim.models.word2vec:PROGRESS: at sentence #30000, processed 367566 words, keeping 6925 word types\n",
      "INFO:MainThread:gensim.models.word2vec:PROGRESS: at sentence #40000, processed 422373 words, keeping 6965 word types\n",
      "INFO:MainThread:gensim.models.word2vec:PROGRESS: at sentence #50000, processed 469363 words, keeping 6980 word types\n",
      "INFO:MainThread:gensim.models.word2vec:PROGRESS: at sentence #60000, processed 509557 words, keeping 6990 word types\n",
      "INFO:MainThread:gensim.models.word2vec:PROGRESS: at sentence #70000, processed 544166 words, keeping 7002 word types\n",
      "INFO:MainThread:gensim.models.word2vec:PROGRESS: at sentence #80000, processed 578069 words, keeping 7009 word types\n",
      "INFO:MainThread:gensim.models.word2vec:PROGRESS: at sentence #90000, processed 606954 words, keeping 7022 word types\n",
      "INFO:MainThread:gensim.models.word2vec:PROGRESS: at sentence #100000, processed 635164 words, keeping 7027 word types\n",
      "INFO:MainThread:gensim.models.word2vec:PROGRESS: at sentence #110000, processed 660028 words, keeping 7029 word types\n",
      "INFO:MainThread:gensim.models.word2vec:PROGRESS: at sentence #120000, processed 683898 words, keeping 7032 word types\n",
      "INFO:MainThread:gensim.models.word2vec:PROGRESS: at sentence #130000, processed 705854 words, keeping 7034 word types\n",
      "INFO:MainThread:gensim.models.word2vec:PROGRESS: at sentence #140000, processed 725994 words, keeping 7037 word types\n",
      "INFO:MainThread:gensim.models.word2vec:PROGRESS: at sentence #150000, processed 747094 words, keeping 7040 word types\n",
      "INFO:MainThread:gensim.models.word2vec:PROGRESS: at sentence #160000, processed 765504 words, keeping 7041 word types\n",
      "INFO:MainThread:gensim.models.word2vec:PROGRESS: at sentence #170000, processed 783186 words, keeping 7041 word types\n",
      "INFO:MainThread:gensim.models.word2vec:PROGRESS: at sentence #180000, processed 800310 words, keeping 7041 word types\n",
      "INFO:MainThread:gensim.models.word2vec:PROGRESS: at sentence #190000, processed 816660 words, keeping 7044 word types\n",
      "INFO:MainThread:gensim.models.word2vec:PROGRESS: at sentence #200000, processed 832535 words, keeping 7045 word types\n",
      "INFO:MainThread:gensim.models.word2vec:PROGRESS: at sentence #210000, processed 847023 words, keeping 7046 word types\n",
      "INFO:MainThread:gensim.models.word2vec:PROGRESS: at sentence #220000, processed 861147 words, keeping 7046 word types\n",
      "INFO:MainThread:gensim.models.word2vec:PROGRESS: at sentence #230000, processed 874872 words, keeping 7046 word types\n",
      "INFO:MainThread:gensim.models.word2vec:PROGRESS: at sentence #240000, processed 888313 words, keeping 7047 word types\n",
      "INFO:MainThread:gensim.models.word2vec:PROGRESS: at sentence #250000, processed 906184 words, keeping 7047 word types\n",
      "INFO:MainThread:gensim.models.word2vec:PROGRESS: at sentence #260000, processed 922809 words, keeping 7049 word types\n",
      "INFO:MainThread:gensim.models.word2vec:PROGRESS: at sentence #270000, processed 936427 words, keeping 7049 word types\n",
      "INFO:MainThread:gensim.models.word2vec:PROGRESS: at sentence #280000, processed 948695 words, keeping 7049 word types\n",
      "INFO:MainThread:gensim.models.word2vec:PROGRESS: at sentence #290000, processed 960093 words, keeping 7049 word types\n",
      "INFO:MainThread:gensim.models.word2vec:PROGRESS: at sentence #300000, processed 970700 words, keeping 7049 word types\n",
      "INFO:MainThread:gensim.models.word2vec:collected 7049 word types from a corpus of 971439 raw words and 300717 sentences\n",
      "INFO:MainThread:gensim.models.word2vec:Loading a fresh vocabulary\n",
      "INFO:MainThread:gensim.models.word2vec:effective_min_count=5 retains 6623 unique words (93% of original 7049, drops 426)\n",
      "INFO:MainThread:gensim.models.word2vec:effective_min_count=5 leaves 969963 word corpus (99% of original 971439, drops 1476)\n",
      "INFO:MainThread:gensim.models.word2vec:deleting the raw counts dictionary of 7049 items\n",
      "INFO:MainThread:gensim.models.word2vec:sample=0.001 downsamples 50 most-common words\n",
      "INFO:MainThread:gensim.models.word2vec:downsampling leaves estimated 855232 word corpus (88.2% of prior 969963)\n",
      "INFO:MainThread:gensim.models.word2vec:constructing a huffman tree from 6623 words\n",
      "INFO:MainThread:gensim.models.word2vec:built huffman tree with maximum node depth 18\n",
      "INFO:MainThread:gensim.models.base_any2vec:estimated required memory for 6623 words and 8 dimensions: 5271908 bytes\n",
      "INFO:MainThread:gensim.models.word2vec:resetting layer weights\n",
      "INFO:MainThread:gensim.models.base_any2vec:training model with 3 workers on 6623 vocabulary and 8 features, using sg=0 hs=1 sample=0.001 negative=5 window=5\n",
      "INFO:MainThread:gensim.models.base_any2vec:EPOCH 1 - PROGRESS: at 37.61% examples, 591556 words/s, in_qsize 6, out_qsize 0\n",
      "INFO:MainThread:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:MainThread:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:MainThread:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:MainThread:gensim.models.base_any2vec:EPOCH - 1 : training on 971439 raw words (855194 effective words) took 1.4s, 616347 effective words/s\n",
      "INFO:MainThread:gensim.models.base_any2vec:EPOCH 2 - PROGRESS: at 42.06% examples, 614967 words/s, in_qsize 6, out_qsize 0\n",
      "INFO:MainThread:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:MainThread:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:MainThread:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:MainThread:gensim.models.base_any2vec:EPOCH - 2 : training on 971439 raw words (855050 effective words) took 1.3s, 638542 effective words/s\n",
      "INFO:MainThread:gensim.models.base_any2vec:EPOCH 3 - PROGRESS: at 43.51% examples, 624316 words/s, in_qsize 5, out_qsize 0\n",
      "INFO:MainThread:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:MainThread:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:MainThread:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:MainThread:gensim.models.base_any2vec:EPOCH - 3 : training on 971439 raw words (854909 effective words) took 1.3s, 644204 effective words/s\n",
      "INFO:MainThread:gensim.models.base_any2vec:EPOCH 4 - PROGRESS: at 45.11% examples, 629565 words/s, in_qsize 5, out_qsize 0\n",
      "INFO:MainThread:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:MainThread:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:MainThread:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:MainThread:gensim.models.base_any2vec:EPOCH - 4 : training on 971439 raw words (855657 effective words) took 1.3s, 647081 effective words/s\n",
      "INFO:MainThread:gensim.models.base_any2vec:EPOCH 5 - PROGRESS: at 43.51% examples, 624996 words/s, in_qsize 5, out_qsize 0\n",
      "INFO:MainThread:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:MainThread:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:MainThread:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:MainThread:gensim.models.base_any2vec:EPOCH - 5 : training on 971439 raw words (855253 effective words) took 1.3s, 640004 effective words/s\n",
      "INFO:MainThread:gensim.models.base_any2vec:training on a 4857195 raw words (4276063 effective words) took 6.7s, 635526 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22.94 Mb, 8.03 Mb (65.00 %)\n",
      "runtime: 2073.353637933731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███▎      | 1/3 [01:32<03:05, 92.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================== deviceid lng_lat ======================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:MainThread:gensim.models.word2vec:collecting all words and their counts\n",
      "INFO:MainThread:gensim.models.word2vec:PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "INFO:MainThread:gensim.models.word2vec:collected 28886 word types from a corpus of 971439 raw words and 7049 sentences\n",
      "INFO:MainThread:gensim.models.word2vec:Loading a fresh vocabulary\n",
      "INFO:MainThread:gensim.models.word2vec:effective_min_count=5 retains 20383 unique words (70% of original 28886, drops 8503)\n",
      "INFO:MainThread:gensim.models.word2vec:effective_min_count=5 leaves 946493 word corpus (97% of original 971439, drops 24946)\n",
      "INFO:MainThread:gensim.models.word2vec:deleting the raw counts dictionary of 28886 items\n",
      "INFO:MainThread:gensim.models.word2vec:sample=0.001 downsamples 8 most-common words\n",
      "INFO:MainThread:gensim.models.word2vec:downsampling leaves estimated 795349 word corpus (84.0% of prior 946493)\n",
      "INFO:MainThread:gensim.models.word2vec:constructing a huffman tree from 20383 words\n",
      "INFO:MainThread:gensim.models.word2vec:built huffman tree with maximum node depth 18\n",
      "INFO:MainThread:gensim.models.base_any2vec:estimated required memory for 20383 words and 8 dimensions: 16224868 bytes\n",
      "INFO:MainThread:gensim.models.word2vec:resetting layer weights\n",
      "INFO:MainThread:gensim.models.base_any2vec:training model with 3 workers on 20383 vocabulary and 8 features, using sg=0 hs=1 sample=0.001 negative=5 window=5\n",
      "INFO:MainThread:gensim.models.base_any2vec:EPOCH 1 - PROGRESS: at 90.99% examples, 762971 words/s, in_qsize 4, out_qsize 0\n",
      "INFO:MainThread:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:MainThread:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:MainThread:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:MainThread:gensim.models.base_any2vec:EPOCH - 1 : training on 971439 raw words (789845 effective words) took 1.0s, 763797 effective words/s\n",
      "INFO:MainThread:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:MainThread:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:MainThread:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:MainThread:gensim.models.base_any2vec:EPOCH - 2 : training on 971439 raw words (789985 effective words) took 1.0s, 825003 effective words/s\n",
      "INFO:MainThread:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:MainThread:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:MainThread:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:MainThread:gensim.models.base_any2vec:EPOCH - 3 : training on 971439 raw words (790071 effective words) took 0.9s, 851367 effective words/s\n",
      "INFO:MainThread:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:MainThread:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:MainThread:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:MainThread:gensim.models.base_any2vec:EPOCH - 4 : training on 971439 raw words (789778 effective words) took 0.9s, 922787 effective words/s\n",
      "INFO:MainThread:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:MainThread:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:MainThread:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:MainThread:gensim.models.base_any2vec:EPOCH - 5 : training on 971439 raw words (789792 effective words) took 1.0s, 829826 effective words/s\n",
      "INFO:MainThread:gensim.models.base_any2vec:training on a 4857195 raw words (3949471 effective words) took 4.7s, 833132 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.54 Mb, 0.17 Mb (67.50 %)\n",
      "runtime: 2095.6993174552917\n",
      "====================================== lng_lat deviceid ======================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:MainThread:gensim.models.word2vec:collecting all words and their counts\n",
      "INFO:MainThread:gensim.models.word2vec:PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "INFO:MainThread:gensim.models.word2vec:PROGRESS: at sentence #10000, processed 709405 words, keeping 6304 word types\n",
      "INFO:MainThread:gensim.models.word2vec:PROGRESS: at sentence #20000, processed 790029 words, keeping 6868 word types\n",
      "INFO:MainThread:gensim.models.word2vec:collected 7049 word types from a corpus of 971439 raw words and 28886 sentences\n",
      "INFO:MainThread:gensim.models.word2vec:Loading a fresh vocabulary\n",
      "INFO:MainThread:gensim.models.word2vec:effective_min_count=5 retains 6623 unique words (93% of original 7049, drops 426)\n",
      "INFO:MainThread:gensim.models.word2vec:effective_min_count=5 leaves 969963 word corpus (99% of original 971439, drops 1476)\n",
      "INFO:MainThread:gensim.models.word2vec:deleting the raw counts dictionary of 7049 items\n",
      "INFO:MainThread:gensim.models.word2vec:sample=0.001 downsamples 50 most-common words\n",
      "INFO:MainThread:gensim.models.word2vec:downsampling leaves estimated 855232 word corpus (88.2% of prior 969963)\n",
      "INFO:MainThread:gensim.models.word2vec:constructing a huffman tree from 6623 words\n",
      "INFO:MainThread:gensim.models.word2vec:built huffman tree with maximum node depth 18\n",
      "INFO:MainThread:gensim.models.base_any2vec:estimated required memory for 6623 words and 8 dimensions: 5271908 bytes\n",
      "INFO:MainThread:gensim.models.word2vec:resetting layer weights\n",
      "INFO:MainThread:gensim.models.base_any2vec:training model with 3 workers on 6623 vocabulary and 8 features, using sg=0 hs=1 sample=0.001 negative=5 window=5\n",
      "INFO:MainThread:gensim.models.base_any2vec:EPOCH 1 - PROGRESS: at 89.39% examples, 677356 words/s, in_qsize 5, out_qsize 0\n",
      "INFO:MainThread:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:MainThread:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:MainThread:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:MainThread:gensim.models.base_any2vec:EPOCH - 1 : training on 971439 raw words (737896 effective words) took 1.1s, 695508 effective words/s\n",
      "INFO:MainThread:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:MainThread:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:MainThread:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:MainThread:gensim.models.base_any2vec:EPOCH - 2 : training on 971439 raw words (738269 effective words) took 0.8s, 971513 effective words/s\n",
      "INFO:MainThread:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:MainThread:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:MainThread:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:MainThread:gensim.models.base_any2vec:EPOCH - 3 : training on 971439 raw words (738259 effective words) took 1.0s, 764435 effective words/s\n",
      "INFO:MainThread:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:MainThread:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:MainThread:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:MainThread:gensim.models.base_any2vec:EPOCH - 4 : training on 971439 raw words (738337 effective words) took 0.7s, 1036311 effective words/s\n",
      "INFO:MainThread:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:MainThread:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:MainThread:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:MainThread:gensim.models.base_any2vec:EPOCH - 5 : training on 971439 raw words (738079 effective words) took 0.7s, 1077461 effective words/s\n",
      "INFO:MainThread:gensim.models.base_any2vec:training on a 4857195 raw words (3690840 effective words) took 4.2s, 879430 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.20 Mb, 0.72 Mb (67.50 %)\n",
      "runtime: 2115.7690057754517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████▋   | 2/3 [02:14<01:17, 77.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================== newsid lng_lat ======================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:MainThread:gensim.models.word2vec:collecting all words and their counts\n",
      "INFO:MainThread:gensim.models.word2vec:PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "INFO:MainThread:gensim.models.word2vec:PROGRESS: at sentence #10000, processed 210921 words, keeping 20236 word types\n",
      "INFO:MainThread:gensim.models.word2vec:PROGRESS: at sentence #20000, processed 299653 words, keeping 23315 word types\n",
      "INFO:MainThread:gensim.models.word2vec:PROGRESS: at sentence #30000, processed 367566 words, keeping 24742 word types\n",
      "INFO:MainThread:gensim.models.word2vec:PROGRESS: at sentence #40000, processed 422373 words, keeping 25623 word types\n",
      "INFO:MainThread:gensim.models.word2vec:PROGRESS: at sentence #50000, processed 469363 words, keeping 26208 word types\n",
      "INFO:MainThread:gensim.models.word2vec:PROGRESS: at sentence #60000, processed 509557 words, keeping 26621 word types\n",
      "INFO:MainThread:gensim.models.word2vec:PROGRESS: at sentence #70000, processed 544166 words, keeping 26916 word types\n",
      "INFO:MainThread:gensim.models.word2vec:PROGRESS: at sentence #80000, processed 578069 words, keeping 27160 word types\n",
      "INFO:MainThread:gensim.models.word2vec:PROGRESS: at sentence #90000, processed 606954 words, keeping 27364 word types\n",
      "INFO:MainThread:gensim.models.word2vec:PROGRESS: at sentence #100000, processed 635164 words, keeping 27526 word types\n",
      "INFO:MainThread:gensim.models.word2vec:PROGRESS: at sentence #110000, processed 660028 words, keeping 27673 word types\n",
      "INFO:MainThread:gensim.models.word2vec:PROGRESS: at sentence #120000, processed 683898 words, keeping 27800 word types\n",
      "INFO:MainThread:gensim.models.word2vec:PROGRESS: at sentence #130000, processed 705854 words, keeping 27899 word types\n",
      "INFO:MainThread:gensim.models.word2vec:PROGRESS: at sentence #140000, processed 725994 words, keeping 28007 word types\n",
      "INFO:MainThread:gensim.models.word2vec:PROGRESS: at sentence #150000, processed 747094 words, keeping 28108 word types\n",
      "INFO:MainThread:gensim.models.word2vec:PROGRESS: at sentence #160000, processed 765504 words, keeping 28179 word types\n",
      "INFO:MainThread:gensim.models.word2vec:PROGRESS: at sentence #170000, processed 783186 words, keeping 28232 word types\n",
      "INFO:MainThread:gensim.models.word2vec:PROGRESS: at sentence #180000, processed 800310 words, keeping 28277 word types\n",
      "INFO:MainThread:gensim.models.word2vec:PROGRESS: at sentence #190000, processed 816660 words, keeping 28340 word types\n",
      "INFO:MainThread:gensim.models.word2vec:PROGRESS: at sentence #200000, processed 832535 words, keeping 28387 word types\n",
      "INFO:MainThread:gensim.models.word2vec:PROGRESS: at sentence #210000, processed 847023 words, keeping 28424 word types\n",
      "INFO:MainThread:gensim.models.word2vec:PROGRESS: at sentence #220000, processed 861147 words, keeping 28454 word types\n",
      "INFO:MainThread:gensim.models.word2vec:PROGRESS: at sentence #230000, processed 874872 words, keeping 28507 word types\n",
      "INFO:MainThread:gensim.models.word2vec:PROGRESS: at sentence #240000, processed 888313 words, keeping 28557 word types\n",
      "INFO:MainThread:gensim.models.word2vec:PROGRESS: at sentence #250000, processed 906184 words, keeping 28623 word types\n",
      "INFO:MainThread:gensim.models.word2vec:PROGRESS: at sentence #260000, processed 922809 words, keeping 28742 word types\n",
      "INFO:MainThread:gensim.models.word2vec:PROGRESS: at sentence #270000, processed 936427 words, keeping 28805 word types\n",
      "INFO:MainThread:gensim.models.word2vec:PROGRESS: at sentence #280000, processed 948695 words, keeping 28836 word types\n",
      "INFO:MainThread:gensim.models.word2vec:PROGRESS: at sentence #290000, processed 960093 words, keeping 28865 word types\n",
      "INFO:MainThread:gensim.models.word2vec:PROGRESS: at sentence #300000, processed 970700 words, keeping 28885 word types\n",
      "INFO:MainThread:gensim.models.word2vec:collected 28886 word types from a corpus of 971439 raw words and 300717 sentences\n",
      "INFO:MainThread:gensim.models.word2vec:Loading a fresh vocabulary\n",
      "INFO:MainThread:gensim.models.word2vec:effective_min_count=5 retains 20383 unique words (70% of original 28886, drops 8503)\n",
      "INFO:MainThread:gensim.models.word2vec:effective_min_count=5 leaves 946493 word corpus (97% of original 971439, drops 24946)\n",
      "INFO:MainThread:gensim.models.word2vec:deleting the raw counts dictionary of 28886 items\n",
      "INFO:MainThread:gensim.models.word2vec:sample=0.001 downsamples 8 most-common words\n",
      "INFO:MainThread:gensim.models.word2vec:downsampling leaves estimated 795349 word corpus (84.0% of prior 946493)\n",
      "INFO:MainThread:gensim.models.word2vec:constructing a huffman tree from 20383 words\n",
      "INFO:MainThread:gensim.models.word2vec:built huffman tree with maximum node depth 18\n",
      "INFO:MainThread:gensim.models.base_any2vec:estimated required memory for 20383 words and 8 dimensions: 16224868 bytes\n",
      "INFO:MainThread:gensim.models.word2vec:resetting layer weights\n",
      "INFO:MainThread:gensim.models.base_any2vec:training model with 3 workers on 20383 vocabulary and 8 features, using sg=0 hs=1 sample=0.001 negative=5 window=5\n",
      "INFO:MainThread:gensim.models.base_any2vec:EPOCH 1 - PROGRESS: at 26.55% examples, 450503 words/s, in_qsize 4, out_qsize 1\n",
      "INFO:MainThread:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:MainThread:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:MainThread:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:MainThread:gensim.models.base_any2vec:EPOCH - 1 : training on 971439 raw words (795483 effective words) took 1.7s, 464475 effective words/s\n",
      "INFO:MainThread:gensim.models.base_any2vec:EPOCH 2 - PROGRESS: at 34.93% examples, 522488 words/s, in_qsize 6, out_qsize 0\n",
      "INFO:MainThread:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:MainThread:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:MainThread:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:MainThread:gensim.models.base_any2vec:EPOCH - 2 : training on 971439 raw words (795506 effective words) took 1.6s, 507818 effective words/s\n",
      "INFO:MainThread:gensim.models.base_any2vec:EPOCH 3 - PROGRESS: at 32.33% examples, 500767 words/s, in_qsize 6, out_qsize 0\n",
      "INFO:MainThread:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:MainThread:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:MainThread:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:MainThread:gensim.models.base_any2vec:EPOCH - 3 : training on 971439 raw words (795354 effective words) took 1.6s, 496996 effective words/s\n",
      "INFO:MainThread:gensim.models.base_any2vec:EPOCH 4 - PROGRESS: at 40.51% examples, 559078 words/s, in_qsize 5, out_qsize 0\n",
      "INFO:MainThread:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:MainThread:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:MainThread:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:MainThread:gensim.models.base_any2vec:EPOCH - 4 : training on 971439 raw words (795297 effective words) took 1.4s, 557617 effective words/s\n",
      "INFO:MainThread:gensim.models.base_any2vec:EPOCH 5 - PROGRESS: at 40.56% examples, 559296 words/s, in_qsize 5, out_qsize 0\n",
      "INFO:MainThread:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:MainThread:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:MainThread:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:MainThread:gensim.models.base_any2vec:EPOCH - 5 : training on 971439 raw words (795430 effective words) took 1.5s, 545490 effective words/s\n",
      "INFO:MainThread:gensim.models.base_any2vec:training on a 4857195 raw words (3977070 effective words) took 7.8s, 511204 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22.94 Mb, 8.03 Mb (65.00 %)\n",
      "runtime: 2184.097326517105\n",
      "====================================== lng_lat newsid ======================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:MainThread:gensim.models.word2vec:collecting all words and their counts\n",
      "INFO:MainThread:gensim.models.word2vec:PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "INFO:MainThread:gensim.models.word2vec:PROGRESS: at sentence #10000, processed 709405 words, keeping 249870 word types\n",
      "INFO:MainThread:gensim.models.word2vec:PROGRESS: at sentence #20000, processed 790029 words, keeping 262967 word types\n",
      "INFO:MainThread:gensim.models.word2vec:collected 300717 word types from a corpus of 971439 raw words and 28886 sentences\n",
      "INFO:MainThread:gensim.models.word2vec:Loading a fresh vocabulary\n",
      "INFO:MainThread:gensim.models.word2vec:effective_min_count=5 retains 38716 unique words (12% of original 300717, drops 262001)\n",
      "INFO:MainThread:gensim.models.word2vec:effective_min_count=5 leaves 569569 word corpus (58% of original 971439, drops 401870)\n",
      "INFO:MainThread:gensim.models.word2vec:deleting the raw counts dictionary of 300717 items\n",
      "INFO:MainThread:gensim.models.word2vec:sample=0.001 downsamples 0 most-common words\n",
      "INFO:MainThread:gensim.models.word2vec:downsampling leaves estimated 569569 word corpus (100.0% of prior 569569)\n",
      "INFO:MainThread:gensim.models.word2vec:constructing a huffman tree from 38716 words\n",
      "INFO:MainThread:gensim.models.word2vec:built huffman tree with maximum node depth 17\n",
      "INFO:MainThread:gensim.models.base_any2vec:estimated required memory for 38716 words and 8 dimensions: 30817936 bytes\n",
      "INFO:MainThread:gensim.models.word2vec:resetting layer weights\n",
      "INFO:MainThread:gensim.models.base_any2vec:training model with 3 workers on 38716 vocabulary and 8 features, using sg=0 hs=1 sample=0.001 negative=5 window=5\n",
      "INFO:MainThread:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:MainThread:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:MainThread:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:MainThread:gensim.models.base_any2vec:EPOCH - 1 : training on 971439 raw words (485179 effective words) took 1.0s, 495080 effective words/s\n",
      "INFO:MainThread:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:MainThread:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:MainThread:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:MainThread:gensim.models.base_any2vec:EPOCH - 2 : training on 971439 raw words (485179 effective words) took 1.0s, 503079 effective words/s\n",
      "INFO:MainThread:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:MainThread:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:MainThread:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:MainThread:gensim.models.base_any2vec:EPOCH - 3 : training on 971439 raw words (485179 effective words) took 1.0s, 495297 effective words/s\n",
      "INFO:MainThread:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:MainThread:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:MainThread:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:MainThread:gensim.models.base_any2vec:EPOCH - 4 : training on 971439 raw words (485179 effective words) took 1.0s, 488173 effective words/s\n",
      "INFO:MainThread:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:MainThread:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:MainThread:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:MainThread:gensim.models.base_any2vec:EPOCH - 5 : training on 971439 raw words (485179 effective words) took 0.9s, 532248 effective words/s\n",
      "INFO:MainThread:gensim.models.base_any2vec:training on a 4857195 raw words (2425895 effective words) took 4.8s, 500978 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.20 Mb, 0.72 Mb (67.50 %)\n",
      "runtime: 2213.092384815216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [03:52<00:00, 77.45s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('*************************** embedding ***************************')\n",
    "\n",
    "\n",
    "# 之前有个朋友给embedding做了一个我认为非常形象的比喻：\n",
    "# 在非诚勿扰上面，如果你想了解一个女嘉宾，那么你可以看看她都中意过哪些男嘉宾；\n",
    "# 反过来也一样，如果你想认识一个男嘉宾，那么你也可以看看他都选过哪些女嘉宾。\n",
    "\n",
    "\n",
    "def emb(df, f1, f2):\n",
    "    emb_size = 8\n",
    "    print('====================================== {} {} ======================================'.format(f1, f2))\n",
    "    tmp = df.groupby(f1, as_index=False)[f2].agg({'{}_{}_list'.format(f1, f2): list})\n",
    "    sentences = tmp['{}_{}_list'.format(f1, f2)].values.tolist()\n",
    "    del tmp['{}_{}_list'.format(f1, f2)]\n",
    "    for i in range(len(sentences)):\n",
    "        sentences[i] = [str(x) for x in sentences[i]]\n",
    "    model = Word2Vec(sentences, size=emb_size, window=5, min_count=5, sg=0, hs=1, seed=2019)\n",
    "    emb_matrix = []\n",
    "    for seq in sentences:\n",
    "        vec = []\n",
    "        for w in seq:\n",
    "            if w in model:\n",
    "                vec.append(model[w])\n",
    "        if len(vec) > 0:\n",
    "            emb_matrix.append(np.mean(vec, axis=0))\n",
    "        else:\n",
    "            emb_matrix.append([0] * emb_size)\n",
    "\n",
    "    # 为了支持数组多维处理，需要先做一个变换\n",
    "    emb_matrix = np.array(emb_matrix)\n",
    "\n",
    "    for i in range(emb_size):\n",
    "        tmp['{}_{}_emb_{}'.format(f1, f2, i)] = emb_matrix[:, i]\n",
    "    del model, emb_matrix, sentences\n",
    "    tmp = reduce_mem(tmp)\n",
    "    print('runtime:', time.time() - t)\n",
    "    return tmp\n",
    "\n",
    "\n",
    "emb_cols = [\n",
    "    ['deviceid', 'newsid'],\n",
    "    ['deviceid', 'lng_lat'],\n",
    "    ['newsid', 'lng_lat'],\n",
    "    # ...\n",
    "]\n",
    "for f1, f2 in tqdm.tqdm(emb_cols):\n",
    "    df = df.merge(emb(sort_df, f1, f2), on=f1, how='left')\n",
    "    df = df.merge(emb(sort_df, f2, f1), on=f2, how='left')\n",
    "del sort_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================== prepare train & valid  =============================================\n",
      "runtime: 2215.8847935199738\n",
      "========================================================================================================\n"
     ]
    }
   ],
   "source": [
    "print('======================================== prepare train & valid  =============================================')\n",
    "train_df = df[:train_num].reset_index(drop=True)\n",
    "test_df = df[train_num:].reset_index(drop=True)\n",
    "del df\n",
    "gc.collect()\n",
    "\n",
    "train_idx = train_df[train_df['day'] < 10].index.tolist()\n",
    "val_idx = train_df[train_df['day'] == 10].index.tolist()\n",
    "\n",
    "train_x = train_df.iloc[train_idx].reset_index(drop=True)\n",
    "train_y = labels[train_idx]\n",
    "val_x = train_df.iloc[val_idx].reset_index(drop=True)\n",
    "val_y = labels[val_idx]\n",
    "\n",
    "del train_x['day'], val_x['day'], train_df['day'], test_df['day']\n",
    "gc.collect()\n",
    "print('runtime:', time.time() - t)\n",
    "print('========================================================================================================')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================================== training validate ===============================================\n",
      "************** training **************\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\tvalid_0's auc: 0.96415\n",
      "[100]\tvalid_0's auc: 0.965765\n",
      "[150]\tvalid_0's auc: 0.966405\n",
      "[200]\tvalid_0's auc: 0.967514\n",
      "[250]\tvalid_0's auc: 0.968365\n",
      "[300]\tvalid_0's auc: 0.968997\n",
      "[350]\tvalid_0's auc: 0.969744\n",
      "[400]\tvalid_0's auc: 0.970466\n",
      "[450]\tvalid_0's auc: 0.970957\n",
      "[500]\tvalid_0's auc: 0.97133\n",
      "[550]\tvalid_0's auc: 0.971596\n",
      "[600]\tvalid_0's auc: 0.971754\n",
      "[650]\tvalid_0's auc: 0.971802\n",
      "[700]\tvalid_0's auc: 0.971878\n",
      "[750]\tvalid_0's auc: 0.971917\n",
      "[800]\tvalid_0's auc: 0.971969\n",
      "[850]\tvalid_0's auc: 0.972004\n",
      "[900]\tvalid_0's auc: 0.971988\n",
      "[950]\tvalid_0's auc: 0.971983\n",
      "[1000]\tvalid_0's auc: 0.971997\n",
      "[1050]\tvalid_0's auc: 0.971974\n",
      "Early stopping, best iteration is:\n",
      "[854]\tvalid_0's auc: 0.972006\n",
      "runtime: 3306.5877532958984\n"
     ]
    }
   ],
   "source": [
    "print('=============================================== training validate ===============================================')\n",
    "fea_imp_list = []\n",
    "clf = LGBMClassifier(\n",
    "    n_jobs=10,\n",
    "    learning_rate=0.01,\n",
    "    n_estimators=5000,\n",
    "    num_leaves=255,\n",
    "    subsample=0.9,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=2019,\n",
    "    metric=None\n",
    ")\n",
    "\n",
    "print('************** training **************')\n",
    "clf.fit(\n",
    "    train_x, train_y,\n",
    "    eval_set=[(val_x, val_y)],\n",
    "    eval_metric='auc',\n",
    "    categorical_feature=cate_cols,\n",
    "    early_stopping_rounds=200,\n",
    "    verbose=50\n",
    ")\n",
    "print('runtime:', time.time() - t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************** validate predict **************\n",
      "runtime: 3351.4983201026917\n",
      "=============================================== training predict ===============================================\n"
     ]
    }
   ],
   "source": [
    "print('************** validate predict **************')\n",
    "best_rounds = clf.best_iteration_\n",
    "best_auc = clf.best_score_['valid_0']['auc']\n",
    "val_pred = clf.predict_proba(val_x)[:, 1]\n",
    "fea_imp_list.append(clf.feature_importances_)\n",
    "print('runtime:', time.time() - t)\n",
    "\n",
    "print('=============================================== training predict ===============================================')\n",
    "clf = LGBMClassifier(\n",
    "    learning_rate=0.01,\n",
    "    n_estimators=best_rounds,\n",
    "    num_leaves=255,\n",
    "    subsample=0.9,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=2019\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************** training **************\n",
      "[50]\ttraining's binary_logloss: 0.197156\n",
      "[100]\ttraining's binary_logloss: 0.14907\n",
      "[150]\ttraining's binary_logloss: 0.123375\n",
      "[200]\ttraining's binary_logloss: 0.107763\n",
      "[250]\ttraining's binary_logloss: 0.097114\n",
      "[300]\ttraining's binary_logloss: 0.0892855\n",
      "[350]\ttraining's binary_logloss: 0.0828667\n",
      "[400]\ttraining's binary_logloss: 0.0773886\n",
      "[450]\ttraining's binary_logloss: 0.0726693\n",
      "[500]\ttraining's binary_logloss: 0.0686212\n",
      "[550]\ttraining's binary_logloss: 0.0649724\n",
      "[600]\ttraining's binary_logloss: 0.0617316\n",
      "[650]\ttraining's binary_logloss: 0.0587216\n",
      "[700]\ttraining's binary_logloss: 0.0560066\n",
      "[750]\ttraining's binary_logloss: 0.0535048\n",
      "[800]\ttraining's binary_logloss: 0.051272\n",
      "[850]\ttraining's binary_logloss: 0.0492429\n",
      "runtime: 4914.790865182877\n",
      "************** test predict **************\n",
      "runtime: 4929.120410203934\n"
     ]
    }
   ],
   "source": [
    "print('************** training **************')\n",
    "clf.fit(\n",
    "    train_df, labels,\n",
    "    eval_set=[(train_df, labels)],\n",
    "    categorical_feature=cate_cols,\n",
    "    verbose=50\n",
    ")\n",
    "print('runtime:', time.time() - t)\n",
    "\n",
    "print('************** test predict **************')\n",
    "sub = pd.read_csv(path_data + 'sample.csv')\n",
    "# sub['target'] = clf.predict_proba(test_df)[:, 1]\n",
    "clf.predict_proba(test_df)[:, 1]\n",
    "fea_imp_list.append(clf.feature_importances_)\n",
    "print('runtime:', time.time() - t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================================== feat importances ===============================================\n",
      "deviceid = 32448.5\n",
      "device_version = 20985.5\n",
      "newsid = 10619.0\n",
      "lat = 9474.0\n",
      "lng = 9431.5\n",
      "lng_lat = 8485.0\n",
      "netmodel_deviceid_lng_lat_next1_exposure_ts_gap = 3810.5\n",
      "netmodel_deviceid_next1_exposure_ts_gap = 2772.5\n",
      "deviceid_next3_exposure_ts_gap = 2692.0\n",
      "netmodel_deviceid_next3_exposure_ts_gap = 2320.5\n",
      "pos_netmodel_deviceid_next1_exposure_ts_gap = 2185.5\n",
      "deviceid_lng_lat_next3_exposure_ts_gap = 1991.5\n",
      "netmodel_deviceid_lng_lat_next2_exposure_ts_gap = 1957.0\n",
      "netmodel_deviceid_next2_exposure_ts_gap = 1874.0\n",
      "cross_deviceid_newsid_count = 1764.5\n",
      "pos_count = 1733.5\n",
      "deviceid_next1_exposure_ts_gap = 1699.0\n",
      "netmodel_deviceid_lng_lat_next3_exposure_ts_gap = 1688.0\n",
      "pos_netmodel_deviceid_lng_lat_next1_exposure_ts_gap = 1593.5\n",
      "deviceid_next5_exposure_ts_gap = 1490.0\n",
      "deviceid_lng_lat_next1_exposure_ts_gap = 1471.0\n",
      "netmodel_deviceid_next5_exposure_ts_gap = 1409.0\n",
      "netmodel_lng_lat_next1_exposure_ts_gap = 1349.0\n",
      "cross_lng_lat_pos_ent = 1314.0\n",
      "deviceid_newsid_emb_1 = 1216.0\n",
      "cross_deviceid_pos_ent = 1128.5\n",
      "cross_pos_deviceid_count_ratio = 1126.0\n",
      "netmodel_deviceid_next10_exposure_ts_gap = 1058.0\n",
      "newsid_next1_exposure_ts_gap = 1056.0\n",
      "deviceid_lng_lat_next5_exposure_ts_gap = 1055.5\n",
      "pos_deviceid_next1_exposure_ts_gap = 998.5\n",
      "deviceid_next2_exposure_ts_gap = 997.0\n",
      "pos_newsid_next1_exposure_ts_gap = 960.0\n",
      "netmodel_deviceid_lng_lat_next10_exposure_ts_gap = 956.0\n",
      "netmodel_lng_lat_next2_exposure_ts_gap = 899.5\n",
      "pos = 892.0\n",
      "lng_lat_next1_exposure_ts_gap = 874.0\n",
      "cross_pos_lng_lat_count_ratio = 872.5\n",
      "netmodel_deviceid_lng_lat_next5_exposure_ts_gap = 867.0\n",
      "pos_deviceid_lng_lat_next1_exposure_ts_gap = 838.5\n",
      "lng_lat_next3_exposure_ts_gap = 813.5\n",
      "deviceid_lng_lat_next2_exposure_ts_gap = 808.0\n",
      "netmodel_deviceid_prev1_exposure_ts_gap = 782.5\n",
      "cross_deviceid_pos_count_ratio = 770.5\n",
      "netmodel_deviceid_prev5_exposure_ts_gap = 765.0\n",
      "pos_deviceid_lng_lat_next2_exposure_ts_gap = 740.0\n",
      "pos_netmodel_deviceid_prev1_exposure_ts_gap = 735.0\n",
      "netmodel_lng_lat_next3_exposure_ts_gap = 731.5\n",
      "newsid_prev1_exposure_ts_gap = 727.5\n",
      "pos_deviceid_next2_exposure_ts_gap = 713.5\n",
      "cross_pos_netmodel_count = 712.5\n",
      "deviceid_newsid_emb_2 = 707.5\n",
      "pos_netmodel_deviceid_next2_exposure_ts_gap = 689.5\n",
      "netmodel_deviceid_lng_lat_prev1_exposure_ts_gap = 681.5\n",
      "pos_netmodel_lng_lat_next1_exposure_ts_gap = 671.5\n",
      "pos_netmodel_deviceid_lng_lat_next2_exposure_ts_gap = 665.5\n",
      "netmodel_deviceid_prev10_exposure_ts_gap = 663.0\n",
      "deviceid_next10_exposure_ts_gap = 662.0\n",
      "deviceid_prev1_exposure_ts_gap = 660.5\n",
      "deviceid_newsid_emb_3 = 618.0\n",
      "netmodel_count = 616.0\n",
      "deviceid_lng_lat_prev1_exposure_ts_gap = 607.5\n",
      "newsid_lng_lat_emb_5 = 605.0\n",
      "pos_deviceid_next3_exposure_ts_gap = 594.0\n",
      "netmodel_deviceid_prev3_exposure_ts_gap = 588.5\n",
      "netmodel_lng_lat_prev1_exposure_ts_gap = 565.0\n",
      "netmodel_lng_lat_next10_exposure_ts_gap = 560.0\n",
      "deviceid_lng_lat_next10_exposure_ts_gap = 559.0\n",
      "lng_lat_next2_exposure_ts_gap = 555.5\n",
      "cross_pos_netmodel_ent = 543.5\n",
      "pos_newsid_prev1_exposure_ts_gap = 543.0\n",
      "pos_netmodel_deviceid_next3_exposure_ts_gap = 542.0\n",
      "newsid_deviceid_emb_6 = 536.5\n",
      "lng_lat_next5_exposure_ts_gap = 530.5\n",
      "pos_netmodel_deviceid_prev2_exposure_ts_gap = 516.5\n",
      "cross_lng_lat_pos_count_ratio = 499.0\n",
      "newsid_lng_lat_emb_3 = 494.5\n",
      "cross_newsid_pos_ent = 488.5\n",
      "netmodel_deviceid_prev2_exposure_ts_gap = 478.0\n",
      "lng_lat_prev1_exposure_ts_gap = 476.5\n",
      "cross_netmodel_pos_count_ratio = 474.5\n",
      "pos_deviceid_prev1_exposure_ts_gap = 469.0\n",
      "pos_netmodel_deviceid_next5_exposure_ts_gap = 464.5\n",
      "pos_deviceid_prev2_exposure_ts_gap = 463.5\n",
      "newsid_next2_exposure_ts_gap = 461.0\n",
      "pos_lng_lat_next1_exposure_ts_gap = 459.0\n",
      "pos_lng_lat_next2_exposure_ts_gap = 459.0\n",
      "pos_netmodel_deviceid_prev3_exposure_ts_gap = 458.5\n",
      "newsid_lng_lat_emb_4 = 456.5\n",
      "cross_newsid_pos_count_ratio = 455.0\n",
      "deviceid_prev10_exposure_ts_gap = 454.0\n",
      "newsid_deviceid_emb_3 = 453.0\n",
      "pos_deviceid_prev10_exposure_ts_gap = 449.0\n",
      "pos_deviceid_prev3_exposure_ts_gap = 445.5\n",
      "deviceid_prev5_exposure_ts_gap = 442.5\n",
      "deviceid_prev3_exposure_ts_gap = 439.5\n",
      "pos_deviceid_next5_exposure_ts_gap = 438.5\n",
      "newsid_prev2_exposure_ts_gap = 432.5\n",
      "netmodel_lng_lat_next5_exposure_ts_gap = 431.0\n",
      "deviceid_prev2_exposure_ts_gap = 430.5\n",
      "pos_netmodel_deviceid_prev5_exposure_ts_gap = 430.5\n",
      "netmodel_deviceid_lng_lat_prev5_exposure_ts_gap = 430.0\n",
      "newsid_lng_lat_emb_7 = 427.5\n",
      "netmodel_deviceid_lng_lat_prev2_exposure_ts_gap = 424.5\n",
      "pos_netmodel_deviceid_next10_exposure_ts_gap = 419.0\n",
      "netmodel_deviceid_lng_lat_prev10_exposure_ts_gap = 417.0\n",
      "newsid_next3_exposure_ts_gap = 412.0\n",
      "netmodel_lng_lat_prev2_exposure_ts_gap = 406.0\n",
      "netmodel_deviceid_lng_lat_prev3_exposure_ts_gap = 404.0\n",
      "cross_newsid_deviceid_count_ratio = 403.0\n",
      "cross_newsid_deviceid_nunique_ratio_newsid_count = 403.0\n",
      "pos_deviceid_next10_exposure_ts_gap = 401.5\n",
      "newsid_lng_lat_emb_1 = 400.5\n",
      "newsid_deviceid_emb_0 = 392.0\n",
      "lng_lat_next10_exposure_ts_gap = 390.0\n",
      "pos_deviceid_prev5_exposure_ts_gap = 389.5\n",
      "pos_lng_lat_prev1_exposure_ts_gap = 384.0\n",
      "pos_netmodel_deviceid_prev10_exposure_ts_gap = 382.0\n",
      "netmodel_lng_lat_prev5_exposure_ts_gap = 377.5\n",
      "newsid_lng_lat_emb_6 = 377.5\n",
      "pos_netmodel_deviceid_lng_lat_next3_exposure_ts_gap = 374.5\n",
      "deviceid_lng_lat_prev2_exposure_ts_gap = 373.0\n",
      "lng_lat_prev3_exposure_ts_gap = 371.0\n",
      "lng_lat_prev2_exposure_ts_gap = 368.0\n",
      "netmodel_lng_lat_prev3_exposure_ts_gap = 368.0\n",
      "newsid_lng_lat_emb_0 = 368.0\n",
      "netmodel_lng_lat_prev10_exposure_ts_gap = 367.0\n",
      "newsid_deviceid_emb_4 = 366.5\n",
      "newsid_deviceid_emb_2 = 364.0\n",
      "newsid_next5_exposure_ts_gap = 361.0\n",
      "cross_pos_lng_lat_nunique_ratio_pos_count = 360.5\n",
      "pos_netmodel_lng_lat_prev1_exposure_ts_gap = 358.0\n",
      "deviceid_lng_lat_prev5_exposure_ts_gap = 356.5\n",
      "minute = 347.0\n",
      "pos_deviceid_lng_lat_prev2_exposure_ts_gap = 347.0\n",
      "pos_netmodel_lng_lat_next2_exposure_ts_gap = 345.0\n",
      "pos_netmodel_lng_lat_next3_exposure_ts_gap = 345.0\n",
      "cross_pos_newsid_count_ratio = 345.0\n",
      "cross_deviceid_pos_count = 343.0\n",
      "deviceid_lng_lat_prev3_exposure_ts_gap = 342.5\n",
      "pos_netmodel_deviceid_lng_lat_prev1_exposure_ts_gap = 342.0\n",
      "newsid_prev3_exposure_ts_gap = 340.5\n",
      "lng_lat_prev10_exposure_ts_gap = 339.5\n",
      "pos_deviceid_lng_lat_prev1_exposure_ts_gap = 333.5\n",
      "cross_deviceid_pos_nunique_ratio_deviceid_count = 332.5\n",
      "lng_lat_prev5_exposure_ts_gap = 329.5\n",
      "pos_netmodel_lng_lat_prev2_exposure_ts_gap = 327.5\n",
      "pos_netmodel_deviceid_lng_lat_prev2_exposure_ts_gap = 325.0\n",
      "pos_lng_lat_next3_exposure_ts_gap = 319.5\n",
      "pos_netmodel_lng_lat_prev10_exposure_ts_gap = 318.5\n",
      "pos_deviceid_lng_lat_next5_exposure_ts_gap = 318.0\n",
      "deviceid_newsid_emb_5 = 316.0\n",
      "pos_deviceid_lng_lat_next3_exposure_ts_gap = 314.0\n",
      "pos_netmodel_deviceid_lng_lat_next5_exposure_ts_gap = 312.5\n",
      "newsid_deviceid_emb_7 = 312.5\n",
      "deviceid_newsid_emb_0 = 310.0\n",
      "newsid_lng_lat_emb_2 = 309.0\n",
      "pos_lng_lat_next5_exposure_ts_gap = 306.0\n",
      "deviceid_lng_lat_prev10_exposure_ts_gap = 305.5\n",
      "cross_newsid_lng_lat_nunique_ratio_newsid_count = 305.5\n",
      "newsid_deviceid_emb_5 = 299.5\n",
      "cross_pos_deviceid_nunique = 297.0\n",
      "pos_deviceid_prev_day_ctr = 292.0\n",
      "pos_deviceid_lng_lat_prev5_exposure_ts_gap = 288.5\n",
      "newsid_prev5_exposure_ts_gap = 287.0\n",
      "pos_lng_lat_prev10_exposure_ts_gap = 286.0\n",
      "cross_netmodel_lng_lat_count_ratio = 285.5\n",
      "pos_lng_lat_next10_exposure_ts_gap = 282.0\n",
      "pos_lng_lat_prev5_exposure_ts_gap = 281.5\n",
      "pos_netmodel_deviceid_lng_lat_prev3_exposure_ts_gap = 280.5\n",
      "pos_newsid_next2_exposure_ts_gap = 280.0\n",
      "newsid_next10_exposure_ts_gap = 279.5\n",
      "pos_netmodel_lng_lat_prev5_exposure_ts_gap = 277.5\n",
      "cross_deviceid_netmodel_count_ratio = 275.0\n",
      "newsid_deviceid_emb_1 = 274.5\n",
      "pos_netmodel_lng_lat_next5_exposure_ts_gap = 273.5\n",
      "deviceid_newsid_emb_4 = 272.0\n",
      "pos_deviceid_lng_lat_prev10_exposure_ts_gap = 271.0\n",
      "pos_lng_lat_prev2_exposure_ts_gap = 270.5\n",
      "pos_netmodel_deviceid_lng_lat_next10_exposure_ts_gap = 270.0\n",
      "pos_lng_lat_prev3_exposure_ts_gap = 263.0\n",
      "pos_deviceid_lng_lat_next10_exposure_ts_gap = 262.5\n",
      "pos_deviceid_lng_lat_prev3_exposure_ts_gap = 259.5\n",
      "cross_netmodel_deviceid_count_ratio = 256.0\n",
      "pos_netmodel_deviceid_lng_lat_prev5_exposure_ts_gap = 255.0\n",
      "cross_newsid_netmodel_ent = 253.0\n",
      "cross_deviceid_pos_nunique = 249.5\n",
      "pos_netmodel_lng_lat_next10_exposure_ts_gap = 248.0\n",
      "cross_newsid_pos_nunique_ratio_newsid_count = 244.0\n",
      "pos_netmodel_deviceid_lng_lat_prev10_exposure_ts_gap = 241.5\n",
      "pos_netmodel_lng_lat_prev3_exposure_ts_gap = 241.0\n",
      "cross_netmodel_newsid_count_ratio = 235.5\n",
      "cross_newsid_lng_lat_count = 230.5\n",
      "cross_pos_netmodel_count_ratio = 230.0\n",
      "pos_newsid_next3_exposure_ts_gap = 229.5\n",
      "cross_pos_deviceid_ent = 222.0\n",
      "pos_newsid_prev2_exposure_ts_gap = 221.0\n",
      "cross_newsid_netmodel_count_ratio = 216.5\n",
      "cross_deviceid_netmodel_count = 209.5\n",
      "cross_deviceid_newsid_count_ratio = 202.5\n",
      "cross_newsid_lng_lat_count_ratio = 199.5\n",
      "cross_deviceid_netmodel_nunique_ratio_deviceid_count = 190.5\n",
      "cross_lng_lat_pos_nunique = 181.0\n",
      "pos_newsid_next5_exposure_ts_gap = 180.0\n",
      "device_version_count = 179.0\n",
      "cross_lng_lat_netmodel_count_ratio = 173.0\n",
      "deviceid_newsid_emb_7 = 166.0\n",
      "newsid_prev10_exposure_ts_gap = 162.0\n",
      "cross_lng_lat_netmodel_ent = 161.0\n",
      "cross_deviceid_lng_lat_nunique_ratio_deviceid_count = 159.5\n",
      "deviceid_count = 158.0\n",
      "cross_newsid_netmodel_nunique_ratio_newsid_count = 155.5\n",
      "pos_deviceid_prev_day_click_count = 149.0\n",
      "lng_lat_newsid_emb_1 = 147.0\n",
      "lng_lat_newsid_emb_3 = 141.5\n",
      "pos_deviceid_prev_day_count = 140.5\n",
      "cross_newsid_lng_lat_ent = 140.5\n",
      "cross_lng_lat_pos_nunique_ratio_lng_lat_count = 137.5\n",
      "cross_lng_lat_deviceid_count_ratio = 134.0\n",
      "pos_newsid_next10_exposure_ts_gap = 129.0\n",
      "cross_newsid_netmodel_count = 126.0\n",
      "lng_lat_newsid_emb_2 = 125.5\n",
      "cross_deviceid_lng_lat_count = 125.0\n",
      "cross_newsid_pos_count = 124.5\n",
      "deviceid_prev_day_ctr = 124.0\n",
      "pos_newsid_prev3_exposure_ts_gap = 123.0\n",
      "cross_pos_newsid_ent = 123.0\n",
      "cross_netmodel_lng_lat_count = 122.0\n",
      "cross_lng_lat_newsid_count_ratio = 121.0\n",
      "deviceid_prev_day_count = 108.5\n",
      "deviceid_newsid_emb_6 = 108.0\n",
      "hour = 103.0\n",
      "cross_pos_lng_lat_count = 101.0\n",
      "deviceid_lng_lat_emb_6 = 101.0\n",
      "lng_lat_newsid_emb_4 = 99.5\n",
      "cross_deviceid_netmodel_ent = 98.0\n",
      "cross_lng_lat_deviceid_nunique_ratio_lng_lat_count = 98.0\n",
      "lng_lat_newsid_emb_6 = 96.5\n",
      "pos_newsid_prev5_exposure_ts_gap = 95.5\n",
      "cross_deviceid_newsid_nunique_ratio_deviceid_count = 94.0\n",
      "deviceid_lng_lat_emb_0 = 92.5\n",
      "deviceid_lng_lat_emb_1 = 90.5\n",
      "cross_newsid_deviceid_ent = 90.0\n",
      "lng_lat_newsid_emb_0 = 90.0\n",
      "lng_lat_deviceid_emb_1 = 89.5\n",
      "lat_count = 86.5\n",
      "deviceid_lng_lat_emb_3 = 86.5\n",
      "cross_deviceid_newsid_nunique = 86.0\n",
      "lng_count = 84.0\n",
      "lng_lat_deviceid_emb_7 = 83.0\n",
      "lng_lat_deviceid_emb_5 = 82.5\n",
      "cross_deviceid_lng_lat_ent = 82.0\n",
      "deviceid_lng_lat_emb_4 = 81.5\n",
      "deviceid_lng_lat_emb_7 = 81.5\n",
      "newsid_count = 80.0\n",
      "deviceid_prev_day_click_count = 80.0\n",
      "deviceid_lng_lat_emb_5 = 80.0\n",
      "lng_lat_deviceid_emb_6 = 78.5\n",
      "lng_lat_newsid_emb_7 = 77.0\n",
      "lng_lat_deviceid_emb_2 = 73.5\n",
      "pos_newsid_prev10_exposure_ts_gap = 73.0\n",
      "lng_lat_newsid_emb_5 = 73.0\n",
      "lng_lat_deviceid_emb_3 = 72.5\n",
      "lng_lat_deviceid_emb_4 = 69.0\n",
      "deviceid_lng_lat_emb_2 = 67.5\n",
      "cross_deviceid_newsid_ent = 65.5\n",
      "lng_lat_deviceid_emb_0 = 62.5\n",
      "cross_lng_lat_netmodel_nunique_ratio_lng_lat_count = 61.0\n",
      "cross_deviceid_lng_lat_nunique = 55.0\n",
      "cross_newsid_pos_nunique = 54.0\n",
      "cross_pos_deviceid_nunique_ratio_pos_count = 48.0\n",
      "cross_lng_lat_newsid_nunique_ratio_lng_lat_count = 41.0\n",
      "osversion_count = 40.5\n",
      "cross_netmodel_deviceid_nunique = 40.5\n",
      "cross_newsid_lng_lat_nunique = 40.0\n",
      "cross_deviceid_lng_lat_count_ratio = 37.5\n",
      "cross_newsid_deviceid_nunique = 37.0\n",
      "cross_lng_lat_newsid_nunique = 35.0\n",
      "device_vendor_count = 33.5\n",
      "cross_lng_lat_newsid_ent = 31.5\n",
      "app_version_count = 30.5\n",
      "lng_lat_count = 21.0\n",
      "cross_newsid_netmodel_nunique = 15.5\n",
      "cross_netmodel_deviceid_ent = 14.0\n",
      "cross_pos_lng_lat_ent = 11.5\n",
      "cross_netmodel_deviceid_nunique_ratio_netmodel_count = 7.5\n",
      "cross_pos_newsid_nunique_ratio_pos_count = 7.0\n",
      "osversion = 6.0\n",
      "device_vendor = 5.5\n",
      "cross_deviceid_netmodel_nunique = 4.5\n",
      "cross_netmodel_newsid_nunique = 4.0\n",
      "cross_pos_newsid_nunique = 3.5\n",
      "cross_netmodel_pos_ent = 3.5\n",
      "cross_lng_lat_netmodel_nunique = 3.5\n",
      "cross_pos_netmodel_nunique_ratio_pos_count = 3.0\n",
      "cross_lng_lat_deviceid_nunique = 2.0\n",
      "app_version = 0.5\n",
      "cross_netmodel_lng_lat_ent = 0.5\n",
      "netmodel = 0.0\n",
      "cross_pos_netmodel_nunique = 0.0\n",
      "cross_pos_lng_lat_nunique = 0.0\n",
      "cross_netmodel_newsid_ent = 0.0\n",
      "cross_netmodel_newsid_nunique_ratio_netmodel_count = 0.0\n",
      "cross_netmodel_pos_nunique = 0.0\n",
      "cross_netmodel_pos_nunique_ratio_netmodel_count = 0.0\n",
      "cross_netmodel_lng_lat_nunique = 0.0\n",
      "cross_netmodel_lng_lat_nunique_ratio_netmodel_count = 0.0\n",
      "cross_lng_lat_deviceid_ent = 0.0\n"
     ]
    }
   ],
   "source": [
    "print('=============================================== feat importances ===============================================')\n",
    "# 特征重要性可以好好看看\n",
    "fea_imp_dict = dict(zip(train_df.columns.values, np.mean(fea_imp_list, axis=0)))\n",
    "fea_imp_item = sorted(fea_imp_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "for f, imp in fea_imp_item:\n",
    "    print('{} = {}'.format(f, imp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('=============================================== threshold search ===============================================')\n",
    "# f1阈值敏感，所以对阈值做一个简单的迭代搜索。\n",
    "t0 = 0.05\n",
    "v = 0.002\n",
    "best_t = t0\n",
    "best_f1 = 0\n",
    "for step in range(201):\n",
    "    curr_t = t0 + step * v\n",
    "    y = [1 if x >= curr_t else 0 for x in val_pred]\n",
    "    curr_f1 = f1_score(val_y, y)\n",
    "    if curr_f1 > best_f1:\n",
    "        best_t = curr_t\n",
    "        best_f1 = curr_f1\n",
    "        print('step: {}   best threshold: {}   best f1: {}'.format(step, best_t, best_f1))\n",
    "print('search finish.')\n",
    "\n",
    "val_pred = [1 if x >= best_t else 0 for x in val_pred]\n",
    "print('\\nbest auc:', best_auc)\n",
    "print('best f1:', f1_score(val_y, val_pred))\n",
    "print('validate mean:', np.mean(val_pred))\n",
    "print('runtime:', time.time() - t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('=============================================== sub save ===============================================')\n",
    "sub.to_csv('sub_prob_{}_{}_{}.csv'.format(best_auc, best_f1, sub['target'].mean()), index=False)\n",
    "sub['target'] = sub['target'].apply(lambda x: 1 if x >= best_t else 0)\n",
    "sub.to_csv('sub_{}_{}_{}.csv'.format(best_auc, best_f1, sub['target'].mean()), index=False)\n",
    "print('runtime:', time.time() - t)\n",
    "print('finish.')\n",
    "print('========================================================================================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
